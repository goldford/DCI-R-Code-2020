{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aed05b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do Feb 6 - see below (need to save the DCI vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "528539bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 5 2022\n",
    "# G Oldford\n",
    "# Purpose - iterate runs of the 'advanced' DCI, store results \n",
    "\n",
    "# code below is cut and paste from FIPEX_run_DCI_DD_2020.r with the main program\n",
    "# modified by encasing it in a function\n",
    "\n",
    "# Setup - ArcMap produces the necessary FIPEX_Advanced_DD_2020.csv and FIPEX_2020_Params.csv\n",
    "# This function reads FIPEX_Advanced ... tab and overwrites the params\n",
    "# then runs and re-runs, storing the output. \n",
    "# It then should join the output files onto the site survey data for Ontario rivers re-analysis\n",
    "\n",
    "# this is a Jupyter R Notebook. \n",
    "# It can be edited and run in a browser\n",
    "# the code debudgged here must be copied to the .r files\n",
    "#R.version\n",
    "\n",
    "#last updated Feb 2022 - G Oldford\n",
    "################################################################\n",
    "# CREATE GRAPH OBJECT for DCI w/ Distance Decay\n",
    "# edge weights are used for distance calculations\n",
    "# edge data / attributes used for habitat quantity calculations\n",
    "# #https://www.rdocumentation.org/packages/graph/versions/1.50.0/topics/graphAM-class\n",
    "create_graph_dd_2020 <- function(adj_matrix_edgelengths=0.0,FIPEX_table=NULL){\n",
    "\n",
    "    # Create graph object\n",
    "    # 2020 - different way to call the graphAM function \n",
    "    # vs pre-2020\n",
    "    g_dd <- graphAM(adjMat=adj_matrix_edgelengths,  edgemode=\"directed\", values=list(weight=1))\n",
    "\n",
    "    # associate passabilities with nodes using NodeData slot\n",
    "    # e.g. nodeData(g,n=c(\"b\", \"c\"), attr =\"color\") <- \"red\"\n",
    "    nodeDataDefaults(g_dd, attr =\"pass\") <- 1.0\n",
    "    nodeData(g_dd,n=as.character(FIPEX_table$NodeEID), attr=\"pass\") <- as.double(FIPEX_table$BarrierPerm)\n",
    "    #nd <- nodes(g_dd)\n",
    "\n",
    "    nodeDataDefaults(g_dd, attr =\"nodelabel\") <- \"none\"\n",
    "    nodeData(g_dd,n=as.character(FIPEX_table$NodeEID), attr=\"nodelabel\") <- as.character(FIPEX_table$NodeLabel)\n",
    "    nodeData(g_dd,n=\"sink\", attr=\"nodelabel\") <- \"sink\"\n",
    "    #nd <- nodes(g_dd)\n",
    "\n",
    "    nodeDataDefaults(g_dd, attr =\"downnodelabel\") <- \"none\"\n",
    "    nodeData(g_dd,n=as.character(FIPEX_table$NodeEID), attr=\"downnodelabel\") <- as.character(FIPEX_table$DownstreamNodeLabel)\n",
    "    #nd <- nodes(g_dd)\n",
    "\n",
    "    nodeDataDefaults(g_dd, attr =\"natural\") <- \"none\"\n",
    "    nodeData(g_dd,n=as.character(FIPEX_table$NodeEID), attr=\"natural\") <- FIPEX_table$NaturalTF\n",
    "    nodeData(g_dd,n=\"sink\", attr=\"natural\") <- FALSE\n",
    "    #nd <- nodes(g_dd)\n",
    "\n",
    "    # optionally can give edges attributes\n",
    "    #edgeDataDefaults(g_dd, attr=\"name\")<-\"noname\"\n",
    "    #edgeData(self, from, to, attr)\n",
    "    #edgeData(self, from, to, attr) <- value\n",
    "    edgeDataDefaults(g_dd, attr=\"HabitatQuan\")<-0.0\n",
    "    edgeData(g_dd,from=as.character(FIPEX_table$NodeEID), \n",
    "         to=as.character(FIPEX_table$DownstreamEID), \n",
    "         attr=\"HabitatQuan\")<-as.double(FIPEX_table$HabQuantity)\n",
    "    # reverse - attr associated with each direction along one edge\n",
    "    edgeData(g_dd,from=as.character(FIPEX_table$DownstreamEID), \n",
    "         to=as.character(FIPEX_table$NodeEID), \n",
    "         attr=\"HabitatQuan\")<-as.double(FIPEX_table$HabQuantity)\n",
    "\n",
    "\n",
    "    # give edges an easy-to-access name insensitive to direction\n",
    "    # this is done to quickly identify duplicates later\n",
    "    # there may be alternatives such as accessing edgeNames but I suspect\n",
    "    # they are slower than this\n",
    "    edgeDataDefaults(g_dd, attr=\"EdgeNameGO\")<-\"init\"\n",
    "    edgeData(g_dd,from=as.character(FIPEX_table$NodeEID), \n",
    "         to=as.character(FIPEX_table$DownstreamEID), \n",
    "         attr=\"EdgeNameGO\")<-paste(as.character(FIPEX_table$DownstreamEID),\n",
    "                                   as.character(FIPEX_table$NodeEID),\n",
    "                                   sep=\"-\")\n",
    "    # reverse - attr associated with each direction along one edge\n",
    "    edgeData(g_dd,from=as.character(FIPEX_table$DownstreamEID), \n",
    "         to=as.character(FIPEX_table$NodeEID), \n",
    "         attr=\"EdgeNameGO\")<-paste(as.character(FIPEX_table$DownstreamEID),\n",
    "                                   as.character(FIPEX_table$NodeEID),\n",
    "                                   sep=\"-\")\n",
    "    return(g_dd)\n",
    "}\n",
    "\n",
    "################################################################################\n",
    "# get all distances and paths (from penult) to all nodes from Sink / all nodes\n",
    "# https://www.rdocumentation.org/packages/RBGL/versions/1.48.1/topics/dijkstra.sp\n",
    "# note it must be node-node - no edge-edge possible\n",
    "# note using this function repeatedly during DCIp is inefficient \n",
    "# !!! (should use BFS w/ LCA i.e., custom algorithm) !!!\n",
    "#   (cannot edit the source for Djikstra.sp because it's actually an \n",
    "#   interface to C++ 'Boost'library for graphs - can't get edge and node attributes \n",
    "#   during net traversal)\n",
    "\n",
    "get_paths_distances <- function(g=NULL,fromnode=\"sink\"){\n",
    "    dijkstra.sp(g,fromnode,eW=unlist(edgeWeights(g)))\n",
    "    \n",
    "    # TO DO: ALTERNATIVES FOR BENCHMARKING\n",
    "}\n",
    "\n",
    "##############################################################################\n",
    "##### SUMMARY TABLE 2020 #####\n",
    "\n",
    "# replaces similar pre-2020 function to create a table for each edge-edge pair\n",
    "# Includes options for alternative data management for benchmarking\n",
    "# (code could be trimmed).\n",
    "# this function could be sped up with custom algorithm that can find path \n",
    "# while also grabbing attribute data (BFS w/ LCA). \n",
    "# - G Oldford, 2020\n",
    "\n",
    "# gets cumulative passability each pair using path info\n",
    "# and get other attributes\n",
    "\n",
    "# pseudocode:\n",
    "# for each 'from node' (e.g., sink in DCId, and all nodes in DCIp)\n",
    "#  get paths between node and all other node\n",
    "#\n",
    "#  for each 'to node' in 'all paths' results\n",
    "#   get the first edge len and hab traversed from node to sink\n",
    "#\n",
    "#   store length and hab of the edge between 'to node' and first node encountered\n",
    "#   in path back to 'from node' (i.e., the 'to edge')\n",
    "\n",
    "#   do while next node name <> \"from node\"\n",
    "#     pass = nodeData(g_dd, nextnode, \"pass\")\n",
    "#     cumulativepass =  cumulativepass * pass\n",
    "#     nextnode = the next node in path towards 'from node'\n",
    "#     if last edge traversed on the way to 'from node'\n",
    "#       store the length and habitat of this edge which is the 'from edge'\n",
    "#     if there is a maxdistance set for distance decay, \n",
    "#       add a TRUE/FALSE column to indicate this\n",
    "#   \n",
    "#   \n",
    "#   add various other attributes to master table (attr's from g object)\n",
    "\n",
    "# requires library(data.table)\n",
    "# data.table vs other options likely to speed things up for large networks\n",
    "#https://rstudio-pubs-static.s3.amazonaws.com/406521_7fc7b6c1dc374e9b8860e15a699d8bb0.html\n",
    "#https://www.rdocumentation.org/packages/data.table/versions/1.13.0/topics/rbindlist\n",
    "\n",
    "get_summary_tab_2020 <- function(option=\"dt-lists\",\n",
    "                                 naturalonly=FALSE,\n",
    "                                 g = NULL,\n",
    "                                 DCIp=FALSE,\n",
    "                                 bDistanceLim=FALSE,\n",
    "                                 dMaxDist=0.0){\n",
    "    \n",
    "    # funciton params:\n",
    "    # option - for benchmarking speed of appending to table\n",
    "    # naturalonly - will calculate pass-weighted path distances\n",
    "    #  while ignoring non-natural barriers\n",
    "    # g - the graph object (rbgl GraphAM in BioconductR)\n",
    "    # DCIp - TRUE / FALSE will trigger loop that finds path\n",
    "    #       between all nodes, node just sink\n",
    "    # initialize empty data object in different ways\n",
    "    \n",
    "    # for different options and benchmarking:\n",
    "    DT2 = data.table(FromNode=\"init\",\n",
    "                 ToNode=\"init\",\n",
    "                 FromNodeLabel=\"init\",\n",
    "                 ToNodeLabel=\"init\",\n",
    "                 CumulativePass=0.0,\n",
    "                 FromEdgeLen=0.0,\n",
    "                 ToEdgeLen=0.0,\n",
    "                 TotalDist=0.0,\n",
    "                 DistMinusStartEndLen=0.0,\n",
    "                 DistMinusSEExceedsThreshold=FALSE,\n",
    "                 FromEdgeHab=0.0,\n",
    "                 ToEdgeHab=0.0,\n",
    "                 ToEdgeName=\"init\",\n",
    "                 FromEdgeName=\"init\",\n",
    "                 ToFromEdgeNameCombo=\"init\")\n",
    "    \n",
    "    DF2 = data.frame(FromNode=\"init\",\n",
    "                 ToNode=\"init\",\n",
    "                 FromNodeLabel=\"init\",\n",
    "                 ToNodeLabel=\"init\",\n",
    "                 CumulativePass=0.0,\n",
    "                 FromEdgeLen=0.0,\n",
    "                 ToEdgeLen=0.0,\n",
    "                 TotalDist=0.0,\n",
    "                 DistMinusStartEndLen=0.0,\n",
    "                 DistMinusSEExceedsThreshold=FALSE,\n",
    "                 FromEdgeHab=0.0,\n",
    "                 ToEdgeHab=0.0,\n",
    "                 ToEdgeName=\"init\",\n",
    "                 FromEdgeName=\"init\",\n",
    "                 ToFromEdgeNameCombo=\"init\", stringsAsFactors=F)\n",
    "    \n",
    "    # lists in R must have size pre-allocated \n",
    "    # size of our table is almost n^2 - n*(n-1) \n",
    "    # (less than n^2 since not getting distance from node to itself)\n",
    "    if(DCIp==FALSE){\n",
    "        outlist <- vector(\"list\", length(numNodes(g_dd)))\n",
    "    }else{\n",
    "        outlist <- vector(\"list\", length(numNodes(g_dd)*(numNodes(g_dd)-1)))   \n",
    "    }\n",
    "    \n",
    "    outlist[[numNodes(g_dd)]] <- list(FromNode=\"init\",\n",
    "                 ToNode=\"init\",\n",
    "                 FromNodeLabel=\"init\",\n",
    "                 ToNodeLabel=\"init\",\n",
    "                 CumulativePass=0.0,\n",
    "                 FromEdgeLen=0.0,\n",
    "                 ToEdgeLen=0.0,\n",
    "                 TotalDist=0.0,\n",
    "                 DistMinusStartEndLen=0.0,\n",
    "                 DistMinusSEExceedsThreshold=FALSE,\n",
    "                 FromEdgeHab=0.0,\n",
    "                 ToEdgeHab=0.0,\n",
    "                 FromEdgeName=\"init\",\n",
    "                 ToEdgeName=\"init\",\n",
    "                 ToFromEdgeNameCombo=\"init\")\n",
    "\n",
    "    # from = sink / start node\n",
    "    # to = other nodes\n",
    "    if(DCIp==FALSE){\n",
    "        fromnodecount=1\n",
    "    }else{\n",
    "        fromnodecount=numNodes(g_dd)\n",
    "    }\n",
    "    \n",
    "    bDistMinusSEExceedsThreshold = FALSE\n",
    "    count = 0\n",
    "    for (j in 1:fromnodecount){\n",
    "        \n",
    "        if(DCIp==FALSE){\n",
    "            fromnode_name = \"sink\"\n",
    "            fromnode_label = \"sink\" \n",
    "        }else{\n",
    "            fromnode_name = nodes(g_dd)[j]\n",
    "             if (fromnode_name==\"sink\"){\n",
    "                fromnode_label = \"sink\"\n",
    "            }else{\n",
    "                fromnode_label = nodeData(g_dd, fromnode_name, \"nodelabel\")[[1]]  \n",
    "            }\n",
    "        }\n",
    "        \n",
    "        ###########################################################\n",
    "        #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        # get path & distances between 'fromnode' and all other nodes\n",
    "        paths_distances <- get_paths_distances(g,fromnode_name)\n",
    "        # this can be time consuming\n",
    "        \n",
    "    for (k in 1:length(paths_distances$penult)) {\n",
    "        \n",
    "        tonode <- paths_distances$penult[k]     \n",
    "        tonode_name = names(tonode)\n",
    "        tonode_name <- tonode_name[[1]]\n",
    "        tonode_label = nodeData(g_dd, tonode_name, \"nodelabel\")[[1]]\n",
    "    \n",
    "        if (tonode_name == fromnode_name){\n",
    "            # not interested in distance from one node to itself\n",
    "            next\n",
    "        }\n",
    "        count = count+1\n",
    "        # initialize\n",
    "        cumulativepass = 1.0\n",
    "        pass = 1.0 # watch not to take pass from to/from end nodes since traversal starts at edge\n",
    "        totaldistance = paths_distances$distances[tonode_name]\n",
    "        totaldistance <- totaldistance[[1]]     \n",
    "        \n",
    "        # get length of edge \n",
    "        nextnode = paths_distances$penult[tonode]\n",
    "        nextnode_name = names(nextnode)\n",
    "        lastnode_name = tonode_name\n",
    "    \n",
    "        # get the last edge length traversed on the way to 'to node'\n",
    "        # alternatively could grab the weight for this edge instead of subtraction\n",
    "        toedgelen = totaldistance - paths_distances$distances[nextnode_name]\n",
    "        toedgelen <- toedgelen[[1]]\n",
    "        toedgedata =edgeData(g_dd, tonode_name,nextnode_name)\n",
    "        toedgehab = toedgedata[[1]]$HabitatQuan\n",
    "        toedgename = toedgedata[[1]]$EdgeNameGO\n",
    "        \n",
    "        exitvar = \"go\"\n",
    "        while (exitvar != \"stop\"){\n",
    "        \n",
    "            if(nextnode_name != fromnode_name){\n",
    "                pass = nodeData(g_dd, nextnode_name, \"pass\")\n",
    "                if(naturalonly==FALSE){\n",
    "                    cumulativepass = cumulativepass * pass[[1]]\n",
    "                }else{\n",
    "                    natural = nodeData(g_dd,nextnode_name,\"natural\")\n",
    "                    if(natural[[1]]==TRUE){\n",
    "                        cumulativepass = cumulativepass * pass[[1]]\n",
    "                    }\n",
    "                }\n",
    "            }else{\n",
    "                fromedgelen = paths_distances$distances[lastnode_name]\n",
    "                fromedgelen <- fromedgelen[[1]]\n",
    "                fromedgedata = edgeData(g_dd, lastnode_name,fromnode_name)\n",
    "                fromedgehab = fromedgedata[[1]]$HabitatQuan\n",
    "                fromedgename = fromedgedata[[1]]$EdgeNameGO\n",
    "                \n",
    "                exitvar=\"stop\"\n",
    "            }\n",
    "            \n",
    "            lastnode_name = nextnode_name\n",
    "            nextnode = paths_distances$penult[nextnode]\n",
    "            nextnode_name = names(nextnode)\n",
    "        }\n",
    "        \n",
    "       distminusstartendlen = totaldistance - toedgelen - fromedgelen\n",
    "       # less than zero distance indicates it's an edge-to-itself distance\n",
    "       # correct for this\n",
    "       if (distminusstartendlen<0){\n",
    "          distminusstartendlen = 0 \n",
    "       }\n",
    "        \n",
    "       tofromedgename_combo = paste(toedgename,fromedgename,sep=\"|\")\n",
    "       \n",
    "       if (bDistanceLim == TRUE){\n",
    "           if (distminusstartendlen > dMaxDist){\n",
    "               bDistMinusSEExceedsThreshold=TRUE\n",
    "           }else{\n",
    "               bDistMinusSEExceedsThreshold=FALSE\n",
    "           }\n",
    "       }else{\n",
    "           bDistMinusSEExceedsThreshold=FALSE\n",
    "       }\n",
    "       \n",
    "        if (option==\"dt\"){\n",
    "            #print(cumulativepass)\n",
    "            #https://www.rdocumentation.org/packages/data.table/versions/1.13.0/topics/rbindlist\n",
    "            DT1 = data.table(FromNode=fromnode_name,\n",
    "                     ToNode=tonode_name,\n",
    "                     FromNodeLabel=fromnode_label,\n",
    "                     ToNodeLabel=tonode_label,\n",
    "                     CumulativePass=cumulativepass, \n",
    "                     FromEdgeLen=fromedgelen,\n",
    "                     ToEdgeLen=toedgelen,\n",
    "                     TotalDist=totaldistance,\n",
    "                     DistMinusStartEndLen=distminusstartendlen,\n",
    "                     DistMinusSEExceedsThreshold = as.logical(bDistMinusSEExceedsThreshold),\n",
    "                     FromEdgeHabLen=fromedgehablen,\n",
    "                     ToEdgeHab=toedgehab,\n",
    "                     FromEdgeHab=fromedgehab,\n",
    "                     FromEdgeName=fromedgename,\n",
    "                     ToEdgeName=toedgename,\n",
    "                     ToFromEdgeNameCombo=tofromedgename_combo)\n",
    "            l = list(DT1,DT2)\n",
    "            \n",
    "            DT2 = rbindlist(l, use.names=TRUE)\n",
    "        }else if(option==\"dt-lists\"){\n",
    "            # append lists to list rather than work yet with tables\n",
    "            DL1 = list(FromNode=fromnode_name,\n",
    "                     ToNode=tonode_name,\n",
    "                     FromNodeLabel=fromnode_label,\n",
    "                     ToNodeLabel=tonode_label,\n",
    "                     CumulativePass=cumulativepass, \n",
    "                     FromEdgeLen=fromedgelen,\n",
    "                     ToEdgeLen=toedgelen,\n",
    "                     TotalDist=totaldistance,\n",
    "                     DistMinusStartEndLen=distminusstartendlen,\n",
    "                     DistMinusSEExceedsThreshold = as.logical(bDistMinusSEExceedsThreshold),\n",
    "                     FromEdgeHab=fromedgehab,\n",
    "                     ToEdgeHab=toedgehab,\n",
    "                     FromEdgeName=fromedgename,\n",
    "                     ToEdgeName=toedgename,\n",
    "                     ToFromEdgeNameCombo=tofromedgename_combo)\n",
    "            #print(\"Length DL1: \")\n",
    "            #print(length(DL1))\n",
    "            outlist[[count]] <- (DL1)\n",
    "            \n",
    "        }else if(option==\"df\"){\n",
    "            DF1 = data.frame(FromNode=fromnode_name,\n",
    "                     ToNode=tonode_name,\n",
    "                     FromNodeLabel=fromnode_label,\n",
    "                     ToNodeLabel=tonode_label,\n",
    "                     CumulativePass=cumulativepass, \n",
    "                     FromEdgeLen=fromedgelen,\n",
    "                     ToEdgeLen=toedgelen,\n",
    "                     TotalDist=totaldistance,\n",
    "                     DistMinusStartEndLen=distminusstartendlen,\n",
    "                     DistMinusSEExceedsThreshold = as.logical(bDistMinusSEExceedsThreshold),\n",
    "                     FromEdgeHab=fromedgehab,\n",
    "                     ToEdgeHab=toedgehab,\n",
    "                     FromEdgeName=fromedgename,\n",
    "                     ToEdgeName=toedgename,\n",
    "                     ToFromEdgeNameCombo=tofromedgename_combo)\n",
    "            #print(fromedgehabarea)\n",
    "            #print(DF1)\n",
    "            DF2 <- rbind(DF2, DF1)\n",
    "          }else if(option==\"df-lists\"){\n",
    "            DL1 = list(FromNode=as.character(fromnode_name),\n",
    "                     ToNode=as.character(tonode_name),\n",
    "                     FromNodeLabel=as.character(fromnode_label),\n",
    "                     ToNodeLabel=as.character(tonode_label),\n",
    "                     CumulativePass=as.numeric(cumulativepass), \n",
    "                     FromEdgeLen=as.numeric(fromedgelen),\n",
    "                     ToEdgeLen=as.numeric(toedgelen),\n",
    "                     TotalDist=as.numeric(totaldistance),\n",
    "                     DistMinusStartEndLen=as.numeric(distminusstartendlen),\n",
    "                     DistMinusSEExceedsThreshold = as.logical(bDistMinusSEExceedsThreshold),\n",
    "                     FromEdgeHab=fromedgehab,\n",
    "                     ToEdgeHab=toedgehab,\n",
    "                     FromEdgeName=as.character(fromedgename),\n",
    "                     ToEdgeName=as.character(toedgename),\n",
    "                     ToFromEdgeNameCombo=as.character(tofromedgename_combo))\n",
    "            outlist[[count]] <- (DL1)\n",
    "        }else if(option==\"dplyr\"){\n",
    "             DL1 = list(FromNode=as.character(fromnode_name),\n",
    "                     ToNode=as.character(tonode_name),\n",
    "                     FromNodeLabel=as.character(fromnode_label),\n",
    "                     ToNodeLabel=as.character(tonode_label),\n",
    "                     CumulativePass=as.numeric(cumulativepass), \n",
    "                     FromEdgeLen=as.numeric(fromedgelen),\n",
    "                     ToEdgeLen=as.numeric(toedgelen),\n",
    "                     TotalDist=as.numeric(totaldistance),\n",
    "                     DistMinusStartEndLen=as.numeric(distminusstartendlen),\n",
    "                     DistMinusSEExceedsThreshold = as.logical(bDistMinusSEExceedsThreshold),\n",
    "                     FromEdgeHab=as.numeric(fromedgehab),\n",
    "                     ToEdgeHab=as.numeric(toedgehab),\n",
    "                     FromEdgeName=fromedgename,\n",
    "                     ToEdgeName=toedgename,\n",
    "                     ToFromEdgeNameCombo=tofromedgename_combo)\n",
    "            #print(row1)\n",
    "            DF2 <- bind_rows(DF2,DL1)\n",
    "        }\n",
    "    } #k\n",
    "    } #j\n",
    "        \n",
    "    if(option==\"dt\"){\n",
    "        sum_tab <- DT2\n",
    "    }else if(option==\"dt-lists\"){\n",
    "        DT2 <- data.table(rbindlist(outlist))\n",
    "        \n",
    "        sum_tab <- DT2\n",
    "    }else if(option==\"df\"){\n",
    "        #DF2 <- DF2[!duplicated(DF2$ToFromEdgeNameCombo), ]\n",
    "        sum_tab <- DF2\n",
    "    }else if(option==\"df-lists\"){\n",
    "        DF2 <- data.frame(do.call(rbind, outlist))\n",
    "        #DF2 <- DF2[!duplicated(DF2$ToFromEdgeNameCombo), ]\n",
    "        sum_tab <- DF2\n",
    "    }else if(option==\"dplyr\"){\n",
    "        sum_tab <- DF2\n",
    "    }\n",
    "        \n",
    "    # if a distance limit, eliminate rows\n",
    "    if(bDistanceLim == TRUE){\n",
    "        return(sum_tab[DistMinusSEExceedsThreshold==FALSE])\n",
    "    }else{\n",
    "        return(sum_tab) \n",
    "    } \n",
    "          \n",
    "}\n",
    "\n",
    "#######################################################\n",
    "###### Calculate DCI #####\n",
    "#dci_calc_2020_dd <- function(){}\n",
    "# warning: the sum_tab_2020 must be a data.table\n",
    "#          only some data frames work ('dplyr' is ok not\n",
    "#          the 'df-lists' option)\n",
    "\n",
    "\n",
    "######### (1) DCId - calc_DCId #########\n",
    "calc_DCId_2020 <- function(sum_tab_2020=NULL,\n",
    "                           totalhabitat=0.0,\n",
    "                           FromNode=\"sink\",\n",
    "                           bDistanceLim=FALSE){\n",
    "    \n",
    "    # filter table\n",
    "    DCId_data<-subset(sum_tab_2020,FromNode==\"sink\")\n",
    "    \n",
    "    # Credit to Chris Edge Code for avoiding loops in R here: \n",
    "    if(bDistanceLim==FALSE){\n",
    "        DCId_data$temp <- DCId_data$CumulativePass * (DCId_data$ToEdgeHab/totalhabitat)\n",
    "    }else{\n",
    "        DCId_data$temp <- DCId_data$CumulativePass * (DCId_data$ToEdgeHabMaxAccessible/DCId_data$MaxTotalAccessHabFromEdge)\n",
    "    }\n",
    "    DCId <- sum(DCId_data$temp)\n",
    "    return(round(DCId*100,2))\n",
    "} # DCId\n",
    "\n",
    "######### (2) DCIp - calc_DCIp #########\n",
    "# Credit to C Edge for shorter code\n",
    "calc_DCIp_2020 <- function(sum_tab_2020=NULL,\n",
    "                           totalhabitat=0.0,\n",
    "                           option=\"unique\",\n",
    "                           bDistanceLim=FALSE){\n",
    "    \n",
    "    # 'option' = unique / distinct for benchmarking speeds\n",
    "    # unique = data.table / base r\n",
    "    # distinct = dplyr\n",
    "    # to do: sometimes sum_tab may be a data.table sometimes data.frame\n",
    "    if(option==\"unique\"){\n",
    "        sum_tab_2020 <- unique(sum_tab_2020, by = \"ToFromEdgeNameCombo\")\n",
    "    }else{\n",
    "        sum_tab_2020 <- distinct(sum_tab_2020, ToFromEdgeNameCombo, .keep_all = TRUE)\n",
    "    }\n",
    "\n",
    "    DCIp <- 0\n",
    "    if(bDistanceLim==FALSE){\n",
    "        for (i in 1:nrow(sum_tab_2020)) {\n",
    "            DCIp <- DCIp + (sum_tab_2020$CumulativePass[i] * (sum_tab_2020$FromEdgeHab[i]/totalhabitat)) * (sum_tab_2020$ToEdgeHab[i]/totalhabitat)\n",
    "        }\n",
    "    }else{\n",
    "        for (i in 1:nrow(sum_tab_2020)) {\n",
    "            DCIp <- DCIp + (sum_tab_2020$CumulativePass[i] * (sum_tab_2020$FromEdgeHab[i]/totalhabitat))* (sum_tab_2020$ToEdgeHabMaxAccessible[i]/sum_tab_2020$MaxTotalAccessHabFromEdge[i]) \n",
    "        }\n",
    "    }\n",
    "    return(round(DCIp*100,2))\n",
    "}\n",
    "\n",
    "######### (3) DCIs - calc_DCIs #########\n",
    "# can be added into (2) as option see below\n",
    "calc_DCIs_2020 <- function (sum_tab_2020=NULL,\n",
    "                            totalhabitat=0.0,\n",
    "                            option=\"dt\",\n",
    "                            bDistanceLim=FALSE){\n",
    "    \n",
    "    # option: \"dt\",\"dplyr\",\"old\"\n",
    "    # alternative methods for benchmarking\n",
    "    if(option==\"dt\"){\n",
    "        \n",
    "        DCIs <- sum_tab_2020\n",
    "        # remove duplicates\n",
    "        DCIs <- unique(sum_tab_2020, by = \"ToFromEdgeNameCombo\")\n",
    "        \n",
    "        if(bDistanceLim==FALSE){\n",
    "            # select only a required columns\n",
    "            cols = c(\"FromEdgeName\",\"ToEdgeHab\",\"CumulativePass\")\n",
    "            DCIs <- DCIs[,..cols]\n",
    "            # first step to DCIs\n",
    "            DCIs[, DCIs_i := round(ToEdgeHab/totalhabitat * CumulativePass * 100,2)]\n",
    "        }else{\n",
    "            # select only a required columns\n",
    "            cols = c(\"FromEdgeName\",\"ToEdgeHabMaxAccessible\",\"CumulativePass\",\"MaxTotalAccessHabFromEdge\")\n",
    "            DCIs <- DCIs[,..cols]\n",
    "            # first step to DCIs\n",
    "            DCIs[, DCIs_i := round(ToEdgeHabMaxAccessible/MaxTotalAccessHabFromEdge * CumulativePass * 100,2)]\n",
    "        }\n",
    "        \n",
    "        cols = c(\"FromEdgeName\",\"DCIs_i\")\n",
    "        DCIs <- DCIs[,..cols]\n",
    "        # second step to DCIs\n",
    "        DCIs <- DCIs[, lapply(.SD,sum), by=.(FromEdgeName)]\n",
    "        \n",
    "    }else if(option==\"dplyr\"){\n",
    "        \n",
    "        if(bDistanceLim==FALSE){\n",
    "            DCIs <- sum_tab_2020 %>%\n",
    "            distinct(ToFromEdgeNameCombo, .keep_all = TRUE) %>%\n",
    "            mutate(DCIs_i = CumulativePass * ToEdgeHab/totalhabitat * 100) %>%\n",
    "            select(DCIs_i,FromEdgeName) %>%\n",
    "            group_by(FromEdgeName) %>%\n",
    "            summarise(DCIs = sum(DCIs_i))\n",
    "        }else{\n",
    "            DCIs <- sum_tab_2020 %>%\n",
    "            distinct(ToFromEdgeNameCombo, .keep_all = TRUE) %>%\n",
    "            mutate(DCIs_i = CumulativePass * ToEdgeHabMaxAccessible/MaxTotalAccessHabFromEdge)*100 %>%\n",
    "            select(DCIs_i,FromEdgeName) %>%\n",
    "            group_by(FromEdgeName) %>%\n",
    "            summarise(DCIs = sum(DCIs_i))\n",
    "        }\n",
    "        \n",
    "        \n",
    "    }else if(option==\"old\"){\n",
    "        sum_tab_2020 <- unique(sum_tab_2020, by = \"ToFromEdgeNameCombo\")\n",
    "        sections<-as.vector(unique(sum_tab_2020$FromEdgeName))\n",
    "        # store the all section results in DCI.as\n",
    "        DCI_as<-NULL\n",
    "        \n",
    "        for(s in 1:length(sections)){\n",
    "            DCI_s<-0\n",
    "            # Old notes:\n",
    "            # select out only the data that corresponds to pathways from one sectino \n",
    "            # to all other sections\n",
    "            d_nrows<-subset(sum_tab_2020, FromEdgeName==sections[s])\n",
    "            d_sum_table<-d_nrows\n",
    "            \n",
    "            if(bDistanceLim==FALSE){\n",
    "                for (a in 1:dim(d_nrows)[1]){\n",
    "                    # Old note:\n",
    "                    #to get the DCI for diadromous fish, use the following formula: \n",
    "                    # DCId= li/L*Cj (where j= the product of the passability in the pathway)\n",
    "                    la<-d_sum_table$ToEdgeHab[a]/sum(FIPEX_table$HabQuantity)\n",
    "                    pass_d<-d_sum_table$CumulativePass[a]\n",
    "                    DCI_s<-round(DCI_s+la*pass_d*100, digits=2)\n",
    "                } # end loop over sections for dci calc\n",
    "            }else{\n",
    "                for (a in 1:dim(d_nrows)[1]){\n",
    "                    # Old note:\n",
    "                    #to get the DCI for diadromous fish, use the following formula: \n",
    "                    # DCId= li/L*Cj (where j= the product of the passability in the pathway)\n",
    "                    la<-d_sum_table$ToEdgeHabMaxAccessible[a]/d_sum_table$MaxTotalAccessHabFromEdge\n",
    "                    pass_d<-d_sum_table$CumulativePass[a]\n",
    "                    DCI_s<-round(DCI_s+la*pass_d*100, digits=2)\n",
    "                } # end loop over sections for dci calc\n",
    "            }\n",
    "            DCI_as[s]<-round(DCI_s*100,2)\n",
    "        } # end loop over \"first\" sections\t\n",
    "\n",
    "        # STORE RESULTS IN .CSV file\n",
    "        DCIs<-data.frame(sections,DCI_as)\n",
    "    }else{\n",
    "        print(\"error in options passed to calc_DCIs\")\n",
    "        DCIs <- 0.0\n",
    "    }\n",
    "    return(DCIs)\n",
    "}\n",
    "\n",
    "apply_distance_limits <- function(sum_tab_2020 = NULL, \n",
    "                                bDistanceLim=FALSE, \n",
    "                                dMaxDist=0.0,\n",
    "                                bDistanceDecay=FALSE,\n",
    "                                sDDFunction=\"none\"){\n",
    "    \n",
    "    ### Calculate proportion of start-end distances for segments < dmax\n",
    "    ### 'a','b' = max,min dist possibly travelled\n",
    "    ### is destination segment reachable? based on min dist 'b'\n",
    "    \n",
    "    \n",
    "    #sum_tab_2020 <- sum_tab_2020 %>%\n",
    "    #mutate(ToEdgeHabProp = (DistMinusStartEndLen+ToEdgeLen-dMaxDist)/ToEdgeLen) %>%\n",
    "    #mutate(ToEdgeHabProp = ifelse(ToEdgeHabProp>=0,1-ToEdgeHabProp,1)) %>%\n",
    "    #mutate(ToEdgeHabMaxAccessible = ToEdgeHabProp * ToEdgeHab) %>%\n",
    "    #select(-ToEdgeHabProp)\n",
    "    \n",
    "    # function changes in 2022\n",
    "    get_max_accessible <- function(DistMinusStartEndLen,ToEdgeLen,\n",
    "                                   ToEdgeHab,dMaxDist,FromEdgeLen, \n",
    "                                   FromEdgeName, ToEdgeName){\n",
    "\n",
    "        reachable_shortest_b = (dMaxDist-DistMinusStartEndLen)/ToEdgeLen\n",
    "        reachable_shortest_b = ifelse(reachable_shortest_b>0,1,reachable_shortest_b)\n",
    "        \n",
    "        prop_reachable_a = ifelse(FromEdgeName==ToEdgeName,\n",
    "                                  (dMaxDist)/ToEdgeLen,\n",
    "                                  (dMaxDist-DistMinusStartEndLen-FromEdgeLen)/ToEdgeLen)\n",
    "        prop_reachable_a = ifelse(prop_reachable_a>0,prop_reachable_a,0)\n",
    "        prop_reachable_a = ifelse(prop_reachable_a>1,1,prop_reachable_a)\n",
    "\n",
    "        \n",
    "        #ifelse statements for vectors, not testing a single val\n",
    "        # numerator is avg of prop_reachable_b (always 1) so removed and prop_reachable_a \n",
    "        toedge_maxaccessible = ifelse(reachable_shortest_b==0,0,((prop_reachable_a * ToEdgeHab)+ ToEdgeHab)/ 2)\n",
    "        print(reachable_shortest_b)\n",
    "        print(prop_reachable_a)\n",
    "        toedge_maxaccessible\n",
    "        \n",
    "        \n",
    "        # old code from 2021\n",
    "#         prop_accessible = (dMaxDist-DistMinusStartEndLen)/ToEdgeLen\n",
    "#         prop_accessible = ifelse(prop_accessible>0,prop_accessible,0)\n",
    "#         prop_accessible = ifelse(prop_accessible>1,1,prop_accessible)\n",
    "#         toedge_maxaccessible = prop_accessible * ToEdgeHab\n",
    "\n",
    "        toedge_maxaccessible\n",
    "    }\n",
    "\n",
    "    sum_tab_2020[, ToEdgeHabMaxAccessible := get_max_accessible(DistMinusStartEndLen,\n",
    "                                                                ToEdgeLen,ToEdgeHab,\n",
    "                                                                dMaxDist,FromEdgeLen,\n",
    "                                                                FromEdgeName, ToEdgeName)]\n",
    "    \n",
    "    if(bDistanceDecay==TRUE & sDDFunction!=\"none\"){\n",
    "        sum_tab_2020 <- apply_distance_decay(sum_tab_2020,sDDFunction,dMaxDist)\n",
    "        # overwriting here because totals below should be based on weighted hab\n",
    "        sum_tab_2020$ToEdgeHabMaxAccessible = sum_tab_2020$toedgehabaccessible_dd\n",
    "    }\n",
    "    \n",
    "    # sum habitat accessible from edge and add as attribute\n",
    "    # in new column \n",
    "    # remove duplicates first...\n",
    "        # to do: dplyr is slower than data.table - re-code and benchmark\n",
    "    sum_tab_hab <- sum_tab_2020 %>% \n",
    "    distinct(ToFromEdgeNameCombo, .keep_all = TRUE) %>%\n",
    "    group_by(FromEdgeName) %>%\n",
    "    summarise(MaxTotalAccessHabFromEdge = sum(ToEdgeHabMaxAccessible))\n",
    "\n",
    "    sum_tab_2020 <- sum_tab_2020 %>%\n",
    "    left_join(sum_tab_hab, by = \"FromEdgeName\", copy=FALSE)\n",
    "    \n",
    "    return(data.table(sum_tab_2020))\n",
    "}\n",
    "\n",
    "apply_distance_decay <- function(sum_tab_2020=NULL,\n",
    "                              sDDFunction=\"none\",\n",
    "                              dMaxDist = 0.0){\n",
    "\n",
    "# distance decay options: \"linear\" - linear (1-x), \n",
    "#                         \"natexp1\"- natural exponential #1 (general form: e^x), \n",
    "#                         \"natexp2\" - natural exponential #2 (general form: e^x^2), \n",
    "#                         \"circle\" - based on equation of circle ((1-x^2)^0.5)\n",
    "#                         \"sigmoid\" - sigmoid (general form:1/(1+e^x)\n",
    "# functions chosen because they can be integrated analytically.\n",
    "# for analytical solutions see documentation. \n",
    "# general form modified so intercepts are (0,1),(1,0) - sometimes approximate\n",
    "# G Oldford, 2020\n",
    "\n",
    "# to do: data.tables with many columns don't perform well and melt() may \n",
    "#        help\n",
    "\n",
    "########## General Formulas ##########\n",
    "#  multiplies the 'maximum accessible habitat' at edge j by f_avg(a,b)\n",
    "# (max accessible is pre-calculated earlier using cut-off value and distance of edge j from edge i)\n",
    "# ===== GO Feb 2022 - changed 'b' to add in the start edge len i (see write-up)\n",
    "# \n",
    "# avg value of a dd function:\n",
    "# f_avg(a,b,f(x)) = 1/(b-a)*integral_a_to_b(f(x)dx)\n",
    "#           represents average value of distance decay function f(x) between \n",
    "#           two positions, a and b, along total distance from end of edge i to maxdist\n",
    "#           where a and b are positions from 0 to maxdist (maxdist is always\n",
    "#           rescaled to 1. \n",
    "# 'a' - proportion of maxdist reached at start of edge j \n",
    "# 'b' - proportion of maxdist reached at end of edge j \n",
    "    e = exp(1)\n",
    "    \n",
    "########## LINEAR distance decay function ##########\n",
    "# function: (1-x) where x is proportion of maxdist\n",
    "# f_avg = ((1-b)+(1-a))/2 \n",
    "# toedgehabaccessible_dd = f_avg(a,b)*ToEdgeHabMaxAccessible\n",
    "    f_avg_linear <- function(a,b) {((1-b)+(1-a))/2}\n",
    "\n",
    "########## natural exponential DD Function #1 ########## \n",
    "########## general form: (-e^x) ##########\n",
    "# parameterized function: f(x) = 1-e^(5(x-5)) with zero intercepts (0,1),(1,0)\n",
    "# integral of f(x) = F_int = x - e^(5(x-1))/5)\n",
    "# f_avg(a,b,f(x)) = 1/(b-a)*(b - e^(5(b-1))/5 -(a - e^(5(a-1))/5))\n",
    "    integral_fx_natexp1 <- function(x){x-e^(5*(x-1))/5}\n",
    "    f_avg_natexp1 <- function(a,b) {(1/(b-a)*(integral_fx_natexp1(b)-integral_fx_natexp1(a)))}\n",
    "\n",
    "########## natural exponential DD Function #2 ########## \n",
    "########## general form: -e^x^2 ##########\n",
    "# parameterized function: f(x) = 2 - e^((x^2)*1/1.44)\n",
    "# integral of f(x) = F_int = ((pi*i)^1/3 * erf(5*i*x/6)) / 5 + 2*x\n",
    "# f_avg(a,b,f(x)) = to do\n",
    "    # Note complete - can't be done without special erfi function \n",
    "    erf <- function(x) 2 * pnorm(x * sqrt(2)) - 1\n",
    "    integral_fx_natexp2 <- function(x){((pi*i)^1/3 * erf(5*i*x/6)) / 5 + 2*x}\n",
    "\n",
    "########## CIRCULAR DD Function ########## \n",
    "########## general form: (1-x^2)^0.5  ##########\n",
    "# parameterized function: f(x) = (1-x^2)^0.5\n",
    "# integral of f(x) = F_int = (asin(x)+x*(1-x^2)^0.5)/2\n",
    "# f_avg(a,b,f(x)) = (asin(b)+b*(1-b^2)^0.5)/2 - (asin(a)+a*(1-a^2)^0.5)/2\n",
    "    integral_fx_circle <- function(x){(asin(x)+x*(1-x^2)^0.5)/2}\n",
    "    f_avg_circle <- function(a,b){((asin(b)+b*(1-b^2)^0.5)/2 - (asin(a)+a*(1-a^2)^0.5)/2)}\n",
    "\n",
    "\n",
    "###### SIGMOID DD function ###### \n",
    "#      general form: 1/(e^x+1))  #\n",
    "# parameterized function: f(x) = 1/(e^(10(x*0.5)))+1\n",
    "# integral f(x) = F_int = x - ln(e^10x+e^5)/10\n",
    "# f_avg(a,b,f(x)) = 1/(b-a)*(b - ln(e^10b+e^5)/10- a - ln(e^10a+e^5)/10)\n",
    "    integral_fx_sigmoid <- function(x){x - log(e^10*x+e^5)/10}\n",
    "    f_avg_sigmoid <- function(a,b) {(1/(b-a)*(integral_fx_sigmoid(b)-integral_fx_sigmoid(a)))}\n",
    "\n",
    "##### Calculate distance-decay weighted habitat accessible ######\n",
    "##### (at each edge j from each each i)\n",
    "# ========= GO Feb 2022 - modified a to be from node at start of line ====\n",
    "    #get_dd_habitat <- function(DistMinusStartEndLen,ToEdgeHabMaxAccessible,dMaxDist,sDDFunction){\n",
    "    get_dd_habitat <- function(DistMinusStartEndLen,ToEdgeHabMaxAccessible,dMaxDist,sDDFunction, FromEdgeLen){\n",
    "        \n",
    "        a = round(DistMinusStartEndLen/dMaxDist,3)\n",
    "        b = round((FromEdgeLen+DistMinusStartEndLen+ToEdgeHabMaxAccessible)/dMaxDist,3)\n",
    "        \n",
    "        a = ifelse(a<0,0,a)\n",
    "        a = ifelse(a>1,1,a)\n",
    "        b = ifelse(b<0,0,b)\n",
    "        b = ifelse(b>1,1,b)\n",
    "   \n",
    "        if(sDDFunction==\"linear\"){\n",
    "            toedgehab_dd <- ToEdgeHabMaxAccessible * f_avg_linear(a,b)\n",
    "        }else if(sDDFunction==\"natexp1\"){\n",
    "            toedgehab_dd <- ToEdgeHabMaxAccessible*f_avg_natexp1(a,b)\n",
    "        }else if(sDDFunction==\"natexp2\"){\n",
    "            # to do\n",
    "        }else if(sDDFunction==\"circle\"){\n",
    "            toedgehab_dd <- ToEdgeHabMaxAccessible*f_avg_circle(a,b)\n",
    "        }else if(sDDFunction==\"sigmoid\"){\n",
    "            toedgehab_dd <- ToEdgeHabMaxAccessible*f_avg_sigmoid(a,b)\n",
    "        }\n",
    "      \n",
    "        # if segment << cutoff distance this can result in NaN's which cause issues.\n",
    "        toedgehab_dd[ is.nan(toedgehab_dd) ] <- 0\n",
    "\n",
    "        toedgehab_dd\n",
    "    }\n",
    "\n",
    "    sum_tab_2020[, toedgehabaccessible_dd := round(get_dd_habitat(DistMinusStartEndLen,\n",
    "                                                                   ToEdgeHabMaxAccessible,\n",
    "                                                                   dMaxDist,\n",
    "                                                                   sDDFunction,\n",
    "                                                                   FromEdgeLen),2)]\n",
    "    return(sum_tab_2020)\n",
    "    \n",
    "}\n",
    "\n",
    "main_program <- function(){\n",
    "# ########################################\n",
    "# ########## MAIN CODE SECTION ############\n",
    "\n",
    "# intialize file with error code\n",
    "write(\"ERROR\",file='out_dd.txt')\n",
    "\n",
    "# RBGL and Rgraphviz must be installed via BioconductR\n",
    "#install.packages(\"BiocManager\")\n",
    "#BiocManager::install(\"Rgraphviz\")\n",
    "#BiocManager::install(\"RBGL\")\n",
    "\n",
    "# optional libraries\n",
    "#library(Rgraphviz) # only needed for visuals\n",
    "#library(rbenchmark) \n",
    "\n",
    "########## 1) DATA PREP #########\n",
    "\n",
    "# 'Advanced' table includes habitat, length, connectivity info in one table\n",
    "FIPEX_table=read.csv(\"FIPEX_Advanced_DD_2020.csv\")\n",
    "# ensure it's \"sink\" not \"Sink\"\n",
    "FIPEX_table <- FIPEX_table %>%\n",
    "mutate(DownstreamEID = ifelse(DownstreamEID == \"Sink\",\"sink\",as.character(DownstreamEID)))\n",
    "\n",
    "# for testing only: natural TF set node 84 to natural barrier\n",
    "#FIPEX_table[2,]$NaturalTF <- TRUE\n",
    "#FIPEX_table\n",
    "\n",
    "# The params file allows users to pass param settings\n",
    "# to R from within the ArcMap software (new in 2020)\n",
    "FIPEX_params=read.csv(\"FIPEX_2020_params.csv\")\n",
    "\n",
    "###### 2) PARAMETERIZATION #######\n",
    "\n",
    "bDCISectional <- as.logical(FIPEX_params$bDCISectional)\n",
    "bDistanceLim <- as.logical(FIPEX_params$bDistanceLim)\n",
    "dMaxDist <- as.double(FIPEX_params$dMaxDist)\n",
    "bDistanceDecay <- as.logical(FIPEX_params$bDistanceDecay)\n",
    "sDDFunction <- as.character(FIPEX_params$sDDFunction)\n",
    "# for testing:\n",
    "#sDDFunction = \"linear\"\n",
    "#sDDFunction = \"natexp1\"\n",
    "#sDDFunction = \"circle\"\n",
    "#sDDFunction = \"sigmoid\"\n",
    "#sDDFunction = \"none\"\n",
    "#bDistanceLim = FALSE\n",
    "#dMaxDist = 1000\n",
    "#bDistanceDecay = FALSE\n",
    "naturalonly = FALSE\n",
    "#bDCISectional = TRUE\n",
    "bDCIp = TRUE\n",
    "\n",
    "totalhabitat = sum(FIPEX_table$HabQuantity)\n",
    "totallength = sum(FIPEX_table$DownstreamNeighDistance)\n",
    "\n",
    "######### 3) NETWORK ANALYSIS #########\n",
    "\n",
    "# build adjacency matrix\n",
    "edgeweighted_adj_matrix <- create_advanced_adjmatrix_2020(FIPEX_table)\n",
    "\n",
    "# build graph object\n",
    "g_dd <- create_graph_dd_2020(edgeweighted_adj_matrix,FIPEX_table)\n",
    "\n",
    "# build summary table (analyses to determine paths, pass, etc between edges)\n",
    "sum_tab_2020 <- get_summary_tab_2020(option=\"dt-lists\",\n",
    "                                     naturalonly,\n",
    "                                     g_dd,\n",
    "                                     bDCIp,\n",
    "                                     bDistanceLim,\n",
    "                                     dMaxDist)\n",
    "\n",
    "if(bDistanceLim==TRUE){\n",
    "    sum_tab_2020 <- apply_distance_limits(sum_tab_2020, bDistanceLim, dMaxDist, bDistanceDecay, sDDFunction)\n",
    "}\n",
    "\n",
    "# for testing: turn all pass = 1 and DCI should = 1\n",
    "#sum_tab_2020<- sum_tab_2020 %>% mutate(CumulativePass=1)\n",
    "#sum_tab_2020 = as.data.table(sum_tab_2020)\n",
    "\n",
    "######## 4) DCI CALC ########\n",
    "DCId = 0.00\n",
    "DCIp = 0.00\n",
    "DCIs = 0.00\n",
    "\n",
    "DCId <- calc_DCId_2020(sum_tab_2020,totalhabitat,\"sink\",bDistanceLim)\n",
    "if(bDCIp==TRUE){\n",
    "    DCIp <- calc_DCIp_2020(sum_tab_2020,totalhabitat,\"unique\",bDistanceLim)\n",
    "\t# sectional can only be run if DCIp has been selected\n",
    "    if(bDCISectional==TRUE){\n",
    "        DCIs <- calc_DCIs_2020(sum_tab_2020,totalhabitat,\"dt\",bDistanceLim)\n",
    "    }\n",
    "}\n",
    "\n",
    "######## 5) Write to Files ######\n",
    "\n",
    "# following previous output format\n",
    "res<- data.frame(c(DCIp,DCId))\n",
    "names(res)<-\"value\"\n",
    "row.names(res)<-c(\"DCIp\",\"DCId\")\n",
    "write.table(res,file='out_dd.txt')\n",
    "\n",
    "# transform data to match what FIPEX expects\n",
    "# DCIs 'FromEdgeName' 100-101 has first numbers as downstream node\n",
    "# to align in FIPEX it can be adjusted to e.g., 100_s\n",
    "# however, this results in more than one segment since, say, node\n",
    "# 100 can have multiple upstream edges and nodes.\n",
    "# To address this the _downstream_ segment DCI_s can be reported\n",
    "# for each node in the system. This change will have to be carefully reported\n",
    "# to the user!\n",
    "if(bDCISectional==TRUE & bDCIp==TRUE){\n",
    "    names(DCIs)[names(DCIs) == 'DCIs_i'] <- 'DCI_as'\n",
    "    names(DCIs)[names(DCIs) == 'FromEdgeName'] <- 'section'\n",
    "    \n",
    "    #DCIs$sections <- paste(sub(\"\\\\-.*\", \"\", DCIs$section),\"_s\",sep=\"\")\n",
    "    # there was a problem encountered with the above because it resulted\n",
    "    # in more than one upstream segment associated with each node. I \n",
    "    # reversed this but now need to be careful that the segmental DCI\n",
    "    # is now reported as associated with the immediate _downstream_\n",
    "    # segement from each node!\n",
    "    DCIs$sections <- paste(sub(\".*\\\\-\", \"\", DCIs$section),\"_s\",sep=\"\")\n",
    "\n",
    "    DCIs$sections[DCIs$sections == \"sink_s\"] <- \"sink\"\n",
    "    DCIs <- DCIs %>% select(sections,DCI_as)\n",
    "    res<-data.frame(DCIs)\n",
    "    write.table(x=res,\n",
    "                file=\"DCI_all_sections_dd.csv\",\n",
    "                sep=\",\",\n",
    "                row.names=F)\n",
    "}\n",
    "    \n",
    "return(res) # added Feb 6 2022 GO\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0268ea77",
   "metadata": {},
   "source": [
    "# Batch run loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b85fecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 1\n",
      "[1] \"C:/Users/Greig/Documents/GitHub/DCI-R-Code-2020/2021 Debug\"\n",
      "[1] \"running model...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in if (reachable_shortest_b == 0) {:\n",
      "\"the condition has length > 1 and only the first element will be used\"`summarise()` ungrouping output (override with `.groups` argument)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 2\n",
      "[1] \"C:/Users/Greig/Documents/GitHub/DCI-R-Code-2020/2021 Debug\"\n",
      "[1] \"running model...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in if (reachable_shortest_b == 0) {:\n",
      "\"the condition has length > 1 and only the first element will be used\"`summarise()` ungrouping output (override with `.groups` argument)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 3\n",
      "[1] \"C:/Users/Greig/Documents/GitHub/DCI-R-Code-2020/2021 Debug\"\n",
      "[1] \"running model...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in if (reachable_shortest_b == 0) {:\n",
      "\"the condition has length > 1 and only the first element will be used\"`summarise()` ungrouping output (override with `.groups` argument)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 4\n",
      "[1] \"C:/Users/Greig/Documents/GitHub/DCI-R-Code-2020/2021 Debug\"\n",
      "[1] \"running model...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in if (reachable_shortest_b == 0) {:\n",
      "\"the condition has length > 1 and only the first element will be used\"`summarise()` ungrouping output (override with `.groups` argument)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 5\n",
      "[1] \"C:/Users/Greig/Documents/GitHub/DCI-R-Code-2020/2021 Debug\"\n",
      "[1] \"running model...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in if (reachable_shortest_b == 0) {:\n",
      "\"the condition has length > 1 and only the first element will be used\"`summarise()` ungrouping output (override with `.groups` argument)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 6\n",
      "[1] \"C:/Users/Greig/Documents/GitHub/DCI-R-Code-2020/2021 Debug\"\n",
      "[1] \"running model...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in if (reachable_shortest_b == 0) {:\n",
      "\"the condition has length > 1 and only the first element will be used\"`summarise()` ungrouping output (override with `.groups` argument)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 7\n",
      "[1] \"C:/Users/Greig/Documents/GitHub/DCI-R-Code-2020/2021 Debug\"\n",
      "[1] \"running model...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in if (reachable_shortest_b == 0) {:\n",
      "\"the condition has length > 1 and only the first element will be used\"`summarise()` ungrouping output (override with `.groups` argument)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 8\n",
      "[1] \"C:/Users/Greig/Documents/GitHub/DCI-R-Code-2020/2021 Debug\"\n",
      "[1] \"running model...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in if (reachable_shortest_b == 0) {:\n",
      "\"the condition has length > 1 and only the first element will be used\"`summarise()` ungrouping output (override with `.groups` argument)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 9\n",
      "[1] \"C:/Users/Greig/Documents/GitHub/DCI-R-Code-2020/2021 Debug\"\n",
      "[1] \"running model...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in if (reachable_shortest_b == 0) {:\n",
      "\"the condition has length > 1 and only the first element will be used\"`summarise()` ungrouping output (override with `.groups` argument)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 10\n",
      "[1] \"C:/Users/Greig/Documents/GitHub/DCI-R-Code-2020/2021 Debug\"\n",
      "[1] \"running model...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in if (reachable_shortest_b == 0) {:\n",
      "\"the condition has length > 1 and only the first element will be used\"`summarise()` ungrouping output (override with `.groups` argument)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Duffins_DCI_all_sections_dd_450_none.csv\"\n",
      "[1] \"Duffins_DCI_all_sections_dd_450_linear.csv\"\n",
      "[1] \"Duffins_DCI_all_sections_dd_1000_none.csv\"\n",
      "[1] \"Duffins_DCI_all_sections_dd_1000_linear.csv\"\n",
      "[1] \"Duffins_DCI_all_sections_dd_5000_none.csv\"\n",
      "[1] \"Duffins_DCI_all_sections_dd_5000_linear.csv\"\n",
      "[1] \"Duffins_DCI_all_sections_dd_10000_none.csv\"\n",
      "[1] \"Duffins_DCI_all_sections_dd_10000_linear.csv\"\n",
      "[1] \"Duffins_DCI_all_sections_dd_25000_none.csv\"\n",
      "[1] \"Duffins_DCI_all_sections_dd_25000_linear.csv\"\n"
     ]
    }
   ],
   "source": [
    "# required libraries\n",
    "library(RBGL) \n",
    "library(data.table) \n",
    "library(tidyverse)\n",
    "\n",
    "systems <- c(\"Duffins\", \"Duffins\", \"Duffins\", \"Duffins\",\n",
    "             \"Duffins\", \"Duffins\", \"Duffins\",\"Duffins\",\n",
    "             \"Duffins\", \"Duffins\")\n",
    "   \n",
    "distances <- c(450,450,1000,1000,\n",
    "               5000,5000,10000,10000,\n",
    "               25000,25000)\n",
    "   \n",
    "functions <- c(\"none\",\"linear\",\"none\",\"linear\",\n",
    "              \"none\",\"linear\",\"none\",\"linear\",\n",
    "              \"none\",\"linear\")\n",
    "    \n",
    "# systems <- c(\"Duffins\",\n",
    "#              \"Duffins\", \"Duffins\", \"Duffins\",\"Duffins\",\n",
    "#              \"Duffins\")\n",
    "   \n",
    "# distances <- c(1000,\n",
    "#                5000,5000,10000,10000,\n",
    "#                25000)\n",
    "   \n",
    "# functions <- c(\"none\",\n",
    "#               \"none\",\"linear\",\"none\",\"linear\",\n",
    "#               \"none\")\n",
    "\n",
    "runinfo_df<- data.frame(systems, distances, functions)\n",
    "\n",
    "DCI_df <- data.frame(system_=character(), distance_lim=double(), \n",
    "                     distance_fnc=character(), DCIp=double(), DCId=double(), \n",
    "                     stringsAsFactors=FALSE) \n",
    "\n",
    "# run DCI analysis\n",
    "for(i in 1:nrow(runinfo_df)) {\n",
    "    row <- runinfo_df[i,]\n",
    "    \n",
    "    FIPEX_param_tab=read.csv(\"FIPEX_2020_Params.csv\")\n",
    "\n",
    "    system = row$systems[1]\n",
    "    distance_lim = row$distances[1]\n",
    "    distance_fnc = row$functions[1]\n",
    "\n",
    "    FIPEX_param_tab['dMaxDist'] = distance_lim\n",
    "    FIPEX_param_tab['sDDFunction'] = distance_fnc\n",
    "    if ( distance_fnc == \"none\" ) {\n",
    "        FIPEX_param_tab['bDistanceDecay'] = \"False\"\n",
    "    }else{\n",
    "        FIPEX_param_tab['bDistanceDecay'] = \"True\"\n",
    "    }\n",
    "    \n",
    "    # change params\n",
    "    write.table(x=FIPEX_param_tab,file=\"FIPEX_2020_Params.csv\",\n",
    "            sep=\",\",row.names=F, quote=FALSE)\n",
    "    \n",
    "    # run model (take a while)\n",
    "    #subprocess.check_output(FIPEX_run_DCI_DD_2020.r)\n",
    "    \n",
    "    print(i)\n",
    "    print(getwd())\n",
    "    print(\"running model...\")\n",
    "    \n",
    "    # this might work for first run but not reliably\n",
    "    DCI_vals = main_program()\n",
    "    \n",
    "    # SAVE DCI \n",
    "    DCI_df %>% add_row(system_=system, distance_lim=distance_lim,\n",
    "                  distance_fnc=distance_fnc, DCIp=DCI_vals[1], DCId=DCI_vals[2])\n",
    "    \n",
    "    # save output of DCIs to individual files\n",
    "    output=read.csv(\"DCI_all_sections_dd.csv\")\n",
    "    out_f = paste(system, \"_DCI_all_sections_dd_\", distance_lim, \"_\", distance_fnc, \".csv\", sep=\"\")\n",
    "    write.table(x=output,file=out_f, sep=\",\",row.names=F, quote=FALSE)\n",
    "    \n",
    "    }\n",
    "\n",
    "surveys_p = \"C:/Users/Greig/Sync/1. UBC-Laptop/42. Ontario Mahlum Re-analysis/3_ReAnalysis_Spring2021/Results/Duffins/\"\n",
    "surveys_f = \"Duffins_FishSurveyDCI.csv\"\n",
    "surveys=read.csv(paste(surveys_p,surveys_f,sep=\"\"))\n",
    "\n",
    "#print(colnames(surveys))\n",
    "\n",
    "# join results to master survey table\n",
    "# can be merged with loop above\n",
    "for(i in 1:nrow(runinfo_df)) {\n",
    "    \n",
    "    row <- runinfo_df[i,]\n",
    "\n",
    "    system = row$systems[1]\n",
    "    distance_lim = row$distances[1]\n",
    "    distance_fnc = row$functions[1]\n",
    "    \n",
    "    path_temp = \"C:/Users/Greig/Sync/1. UBC-Laptop/42. Ontario Mahlum Re-analysis/3_ReAnalysis_Spring2021/Results/Duffins/scenario2_allbarriershighperm/\"\n",
    "\n",
    "    out_f = paste(system, \"_DCI_all_sections_dd_\", distance_lim, \"_\", distance_fnc, \".csv\", sep=\"\")\n",
    "    print(out_f)\n",
    "    output=read.csv(paste(path_temp,out_f,sep=\"\"))\n",
    "    \n",
    "    if (distance_lim >= 1000){\n",
    "        suffix=\"km\"\n",
    "        dis = distance_lim / 1000\n",
    "    }else{\n",
    "        suffix=\"m\"\n",
    "        dis = distance_lim\n",
    "    }\n",
    "\n",
    "    if (distance_fnc == \"linear\"){\n",
    "        fnc = \"Li\"\n",
    "    }else{\n",
    "        fnc=\"Cu\"\n",
    "    }\n",
    "\n",
    "    newcolname = paste(\"S2_DCIs\",dis,suffix,fnc,sep=\"\")\n",
    "    surveys = surveys %>% left_join(output, by = c(\"FIPEX_su_1\"=\"sections\")) %>% rename(!!newcolname := 'DCI_as')\n",
    "    \n",
    "    }\n",
    "\n",
    "surveys_f_out = paste(\"Sc2_\",surveys_f)\n",
    "# fix commas in the 'desc' field messing up CSV\n",
    "surveys = surveys %>% mutate(DESCR = gsub(\",\", \" \", DESCR))\n",
    "write.table(x=surveys,file=surveys_f_out, sep=\",\",row.names=F, quote=FALSE)\n",
    "\n",
    "DCI_f_out = \"DCI_out_allruns_Duffins.csv\"\n",
    "write.table(x=DCI_df,file=DCI_f_out, sep=\",\",row.names=F, quote=FALSE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af739118",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in dijkstra.sp(g, fromnode, eW = unlist(edgeWeights(g))): start not found in nodes of g\n",
     "output_type": "error",
     "traceback": [
      "Error in dijkstra.sp(g, fromnode, eW = unlist(edgeWeights(g))): start not found in nodes of g\nTraceback:\n",
      "1. main_program()",
      "2. get_summary_tab_2020(option = \"dt-lists\", naturalonly, g_dd, \n .     bDCIp, bDistanceLim, dMaxDist)   # at line 828-833 of file <text>",
      "3. get_paths_distances(g, fromnode_name)   # at line 241 of file <text>",
      "4. dijkstra.sp(g, fromnode, eW = unlist(edgeWeights(g)))   # at line 95 of file <text>",
      "5. stop(\"start not found in nodes of g\")"
     ]
    }
   ],
   "source": [
    "DCI_vals = main_program()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d1d810a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'g' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'g' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038ff5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999149f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9a0580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fde7cd2",
   "metadata": {},
   "source": [
    "# Single run test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7d1b5292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " [1] 1.0000000 1.0000000 0.3333333 0.5000000 1.0000000 1.0000000 0.5000000\n",
      " [8] 0.0000000 1.0000000 1.0000000 1.0000000 0.5000000 1.0000000 0.0000000\n",
      "[15] 1.0000000 0.0000000 0.0000000 1.0000000 0.0000000 0.5000000 1.0000000\n",
      "[22] 0.0000000 0.0000000 1.0000000 1.0000000 1.0000000 0.0000000 0.0000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`summarise()` ungrouping output (override with `.groups` argument)\n"
     ]
    }
   ],
   "source": [
    "# intialize file with error code\n",
    "write(\"ERROR\",file='out_dd.txt')\n",
    "\n",
    "# RBGL and Rgraphviz must be installed via BioconductR\n",
    "#install.packages(\"BiocManager\")\n",
    "#BiocManager::install(\"Rgraphviz\")\n",
    "#BiocManager::install(\"RBGL\")\n",
    "\n",
    "# optional libraries\n",
    "#library(Rgraphviz) # only needed for visuals\n",
    "#library(rbenchmark) \n",
    "\n",
    "########## 1) DATA PREP #########\n",
    "\n",
    "# 'Advanced' table includes habitat, length, connectivity info in one table\n",
    "FIPEX_table=read.csv(\"FIPEX_Advanced_DD_2020.csv\")\n",
    "# ensure it's \"sink\" not \"Sink\"\n",
    "FIPEX_table <- FIPEX_table %>%\n",
    "mutate(DownstreamEID = ifelse(DownstreamEID == \"Sink\",\"sink\",as.character(DownstreamEID)))\n",
    "\n",
    "# for testing only: natural TF set node 84 to natural barrier\n",
    "#FIPEX_table[2,]$NaturalTF <- TRUE\n",
    "#FIPEX_table\n",
    "\n",
    "# The params file allows users to pass param settings\n",
    "# to R from within the ArcMap software (new in 2020)\n",
    "FIPEX_params=read.csv(\"FIPEX_2020_params.csv\")\n",
    "\n",
    "###### 2) PARAMETERIZATION #######\n",
    "\n",
    "bDCISectional <- as.logical(FIPEX_params$bDCISectional)\n",
    "bDistanceLim <- as.logical(FIPEX_params$bDistanceLim)\n",
    "dMaxDist <- as.double(FIPEX_params$dMaxDist)\n",
    "bDistanceDecay <- as.logical(FIPEX_params$bDistanceDecay)\n",
    "sDDFunction <- as.character(FIPEX_params$sDDFunction)\n",
    "# for testing:\n",
    "#sDDFunction = \"linear\"\n",
    "#sDDFunction = \"natexp1\"\n",
    "#sDDFunction = \"circle\"\n",
    "#sDDFunction = \"sigmoid\"\n",
    "#sDDFunction = \"none\"\n",
    "#bDistanceLim = FALSE\n",
    "#dMaxDist = 1000\n",
    "#bDistanceDecay = FALSE\n",
    "naturalonly = FALSE\n",
    "#bDCISectional = TRUE\n",
    "bDCIp = TRUE\n",
    "\n",
    "totalhabitat = sum(FIPEX_table$HabQuantity)\n",
    "totallength = sum(FIPEX_table$DownstreamNeighDistance)\n",
    "\n",
    "######### 3) NETWORK ANALYSIS #########\n",
    "\n",
    "# build adjacency matrix\n",
    "edgeweighted_adj_matrix <- create_advanced_adjmatrix_2020(FIPEX_table)\n",
    "\n",
    "# build graph object\n",
    "g_dd <- create_graph_dd_2020(edgeweighted_adj_matrix,FIPEX_table)\n",
    "\n",
    "# build summary table (analyses to determine paths, pass, etc between edges)\n",
    "sum_tab_2020 <- get_summary_tab_2020(option=\"dt-lists\",\n",
    "                                     naturalonly,\n",
    "                                     g_dd,\n",
    "                                     bDCIp,\n",
    "                                     bDistanceLim,\n",
    "                                     dMaxDist)\n",
    "\n",
    "if(bDistanceLim==TRUE){\n",
    "    sum_tab_2020 <- apply_distance_limits(sum_tab_2020, bDistanceLim, dMaxDist, bDistanceDecay, sDDFunction)\n",
    "}\n",
    "\n",
    "# for testing: turn all pass = 1 and DCI should = 1\n",
    "#sum_tab_2020<- sum_tab_2020 %>% mutate(CumulativePass=1)\n",
    "#sum_tab_2020 = as.data.table(sum_tab_2020)\n",
    "\n",
    "######## 4) DCI CALC ########\n",
    "DCId = 0.00\n",
    "DCIp = 0.00\n",
    "DCIs = 0.00\n",
    "\n",
    "DCId <- calc_DCId_2020(sum_tab_2020,totalhabitat,\"sink\",bDistanceLim)\n",
    "if(bDCIp==TRUE){\n",
    "    DCIp <- calc_DCIp_2020(sum_tab_2020,totalhabitat,\"unique\",bDistanceLim)\n",
    "\t# sectional can only be run if DCIp has been selected\n",
    "    if(bDCISectional==TRUE){\n",
    "        DCIs <- calc_DCIs_2020(sum_tab_2020,totalhabitat,\"dt\",bDistanceLim)\n",
    "    }\n",
    "}\n",
    "\n",
    "######## 5) Write to Files ######\n",
    "\n",
    "# following previous output format\n",
    "res<- data.frame(c(DCIp,DCId))\n",
    "names(res)<-\"value\"\n",
    "row.names(res)<-c(\"DCIp\",\"DCId\")\n",
    "write.table(res,file='out_dd.txt')\n",
    "\n",
    "# transform data to match what FIPEX expects\n",
    "# DCIs 'FromEdgeName' 100-101 has first numbers as downstream node\n",
    "# to align in FIPEX it can be adjusted to e.g., 100_s\n",
    "# however, this results in more than one segment since, say, node\n",
    "# 100 can have multiple upstream edges and nodes.\n",
    "# To address this the _downstream_ segment DCI_s can be reported\n",
    "# for each node in the system. This change will have to be carefully reported\n",
    "# to the user!\n",
    "if(bDCISectional==TRUE & bDCIp==TRUE){\n",
    "    names(DCIs)[names(DCIs) == 'DCIs_i'] <- 'DCI_as'\n",
    "    names(DCIs)[names(DCIs) == 'FromEdgeName'] <- 'section'\n",
    "    \n",
    "    #DCIs$sections <- paste(sub(\"\\\\-.*\", \"\", DCIs$section),\"_s\",sep=\"\")\n",
    "    # there was a problem encountered with the above because it resulted\n",
    "    # in more than one upstream segment associated with each node. I \n",
    "    # reversed this but now need to be careful that the segmental DCI\n",
    "    # is now reported as associated with the immediate _downstream_\n",
    "    # segement from each node!\n",
    "    DCIs$sections <- paste(sub(\".*\\\\-\", \"\", DCIs$section),\"_s\",sep=\"\")\n",
    "\n",
    "    DCIs$sections[DCIs$sections == \"sink_s\"] <- \"sink\"\n",
    "    DCIs <- DCIs %>% select(sections,DCI_as)\n",
    "    res<-data.frame(DCIs)\n",
    "    write.table(x=res,\n",
    "                file=\"DCI_all_sections_dd.csv\",\n",
    "                sep=\",\",\n",
    "                row.names=F)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ac6ed020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "77.52"
      ],
      "text/latex": [
       "77.52"
      ],
      "text/markdown": [
       "77.52"
      ],
      "text/plain": [
       "[1] 77.52"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DCIp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bc7e70f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.table: 28 × 17</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>FromNode</th><th scope=col>ToNode</th><th scope=col>FromNodeLabel</th><th scope=col>ToNodeLabel</th><th scope=col>CumulativePass</th><th scope=col>FromEdgeLen</th><th scope=col>ToEdgeLen</th><th scope=col>TotalDist</th><th scope=col>DistMinusStartEndLen</th><th scope=col>DistMinusSEExceedsThreshold</th><th scope=col>FromEdgeHab</th><th scope=col>ToEdgeHab</th><th scope=col>FromEdgeName</th><th scope=col>ToEdgeName</th><th scope=col>ToFromEdgeNameCombo</th><th scope=col>ToEdgeHabMaxAccessible</th><th scope=col>MaxTotalAccessHabFromEdge</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;lgl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>2   </td><td>3   </td><td>4    </td><td>Dam 2</td><td>1.0</td><td>2</td><td>2</td><td>2</td><td>0</td><td>FALSE</td><td>2</td><td>2</td><td>2-3   </td><td>2-3   </td><td>2-3|2-3      </td><td>2.0</td><td>7.5</td></tr>\n",
       "\t<tr><td>2   </td><td>4   </td><td>4    </td><td>Dam 1</td><td>1.0</td><td>2</td><td>2</td><td>2</td><td>0</td><td>FALSE</td><td>2</td><td>2</td><td>2-4   </td><td>2-4   </td><td>2-4|2-4      </td><td>2.0</td><td>7.5</td></tr>\n",
       "\t<tr><td>2   </td><td>5   </td><td>4    </td><td>2    </td><td>0.5</td><td>2</td><td>3</td><td>5</td><td>0</td><td>FALSE</td><td>2</td><td>3</td><td>2-4   </td><td>4-5   </td><td>4-5|2-4      </td><td>2.0</td><td>7.5</td></tr>\n",
       "\t<tr><td>2   </td><td>8   </td><td>4    </td><td>6    </td><td>0.5</td><td>2</td><td>2</td><td>4</td><td>0</td><td>FALSE</td><td>2</td><td>2</td><td>2-3   </td><td>3-8   </td><td>3-8|2-3      </td><td>1.5</td><td>7.5</td></tr>\n",
       "\t<tr><td>2   </td><td>sink</td><td>4    </td><td>sink </td><td>1.0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>FALSE</td><td>1</td><td>1</td><td>sink-2</td><td>sink-2</td><td>sink-2|sink-2</td><td>1.0</td><td>7.5</td></tr>\n",
       "\t<tr><td>3   </td><td>2   </td><td>Dam 2</td><td>4    </td><td>1.0</td><td>2</td><td>2</td><td>2</td><td>0</td><td>FALSE</td><td>2</td><td>2</td><td>2-3   </td><td>2-3   </td><td>2-3|2-3      </td><td>2.0</td><td>7.5</td></tr>\n",
       "\t<tr><td>3   </td><td>4   </td><td>Dam 2</td><td>Dam 1</td><td>1.0</td><td>2</td><td>2</td><td>4</td><td>0</td><td>FALSE</td><td>2</td><td>2</td><td>2-3   </td><td>2-4   </td><td>2-4|2-3      </td><td>1.5</td><td>7.5</td></tr>\n",
       "\t<tr><td>3   </td><td>5   </td><td>Dam 2</td><td>2    </td><td>0.5</td><td>2</td><td>3</td><td>7</td><td>2</td><td>FALSE</td><td>2</td><td>3</td><td>2-3   </td><td>4-5   </td><td>4-5|2-3      </td><td>1.5</td><td>7.5</td></tr>\n",
       "\t<tr><td>3   </td><td>8   </td><td>Dam 2</td><td>6    </td><td>1.0</td><td>2</td><td>2</td><td>2</td><td>0</td><td>FALSE</td><td>2</td><td>2</td><td>3-8   </td><td>3-8   </td><td>3-8|3-8      </td><td>2.0</td><td>5.0</td></tr>\n",
       "\t<tr><td>3   </td><td>sink</td><td>Dam 2</td><td>sink </td><td>1.0</td><td>2</td><td>1</td><td>3</td><td>0</td><td>FALSE</td><td>2</td><td>1</td><td>2-3   </td><td>sink-2</td><td>sink-2|2-3   </td><td>1.0</td><td>7.5</td></tr>\n",
       "\t<tr><td>4   </td><td>2   </td><td>Dam 1</td><td>4    </td><td>1.0</td><td>2</td><td>2</td><td>2</td><td>0</td><td>FALSE</td><td>2</td><td>2</td><td>2-4   </td><td>2-4   </td><td>2-4|2-4      </td><td>2.0</td><td>7.5</td></tr>\n",
       "\t<tr><td>4   </td><td>3   </td><td>Dam 1</td><td>Dam 2</td><td>1.0</td><td>2</td><td>2</td><td>4</td><td>0</td><td>FALSE</td><td>2</td><td>2</td><td>2-4   </td><td>2-3   </td><td>2-3|2-4      </td><td>1.5</td><td>7.5</td></tr>\n",
       "\t<tr><td>4   </td><td>5   </td><td>Dam 1</td><td>2    </td><td>1.0</td><td>3</td><td>3</td><td>3</td><td>0</td><td>FALSE</td><td>3</td><td>3</td><td>4-5   </td><td>4-5   </td><td>4-5|4-5      </td><td>3.0</td><td>5.5</td></tr>\n",
       "\t<tr><td>4   </td><td>8   </td><td>Dam 1</td><td>6    </td><td>0.5</td><td>2</td><td>2</td><td>6</td><td>2</td><td>FALSE</td><td>2</td><td>2</td><td>2-4   </td><td>3-8   </td><td>3-8|2-4      </td><td>1.0</td><td>7.5</td></tr>\n",
       "\t<tr><td>4   </td><td>sink</td><td>Dam 1</td><td>sink </td><td>1.0</td><td>2</td><td>1</td><td>3</td><td>0</td><td>FALSE</td><td>2</td><td>1</td><td>2-4   </td><td>sink-2</td><td>sink-2|2-4   </td><td>1.0</td><td>7.5</td></tr>\n",
       "\t<tr><td>5   </td><td>2   </td><td>2    </td><td>4    </td><td>0.5</td><td>3</td><td>2</td><td>5</td><td>0</td><td>FALSE</td><td>3</td><td>2</td><td>4-5   </td><td>2-4   </td><td>2-4|4-5      </td><td>1.0</td><td>5.5</td></tr>\n",
       "\t<tr><td>5   </td><td>3   </td><td>2    </td><td>Dam 2</td><td>0.5</td><td>3</td><td>2</td><td>7</td><td>2</td><td>FALSE</td><td>3</td><td>2</td><td>4-5   </td><td>2-3   </td><td>2-3|4-5      </td><td>1.0</td><td>5.5</td></tr>\n",
       "\t<tr><td>5   </td><td>4   </td><td>2    </td><td>Dam 1</td><td>1.0</td><td>3</td><td>3</td><td>3</td><td>0</td><td>FALSE</td><td>3</td><td>3</td><td>4-5   </td><td>4-5   </td><td>4-5|4-5      </td><td>3.0</td><td>5.5</td></tr>\n",
       "\t<tr><td>5   </td><td>sink</td><td>2    </td><td>sink </td><td>0.5</td><td>3</td><td>1</td><td>6</td><td>2</td><td>FALSE</td><td>3</td><td>1</td><td>4-5   </td><td>sink-2</td><td>sink-2|4-5   </td><td>0.5</td><td>5.5</td></tr>\n",
       "\t<tr><td>8   </td><td>2   </td><td>6    </td><td>4    </td><td>0.5</td><td>2</td><td>2</td><td>4</td><td>0</td><td>FALSE</td><td>2</td><td>2</td><td>3-8   </td><td>2-3   </td><td>2-3|3-8      </td><td>1.5</td><td>5.0</td></tr>\n",
       "\t<tr><td>8   </td><td>3   </td><td>6    </td><td>Dam 2</td><td>1.0</td><td>2</td><td>2</td><td>2</td><td>0</td><td>FALSE</td><td>2</td><td>2</td><td>3-8   </td><td>3-8   </td><td>3-8|3-8      </td><td>2.0</td><td>5.0</td></tr>\n",
       "\t<tr><td>8   </td><td>4   </td><td>6    </td><td>Dam 1</td><td>0.5</td><td>2</td><td>2</td><td>6</td><td>2</td><td>FALSE</td><td>2</td><td>2</td><td>3-8   </td><td>2-4   </td><td>2-4|3-8      </td><td>1.0</td><td>5.0</td></tr>\n",
       "\t<tr><td>8   </td><td>sink</td><td>6    </td><td>sink </td><td>0.5</td><td>2</td><td>1</td><td>5</td><td>2</td><td>FALSE</td><td>2</td><td>1</td><td>3-8   </td><td>sink-2</td><td>sink-2|3-8   </td><td>0.5</td><td>5.0</td></tr>\n",
       "\t<tr><td>sink</td><td>2   </td><td>sink </td><td>4    </td><td>1.0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>FALSE</td><td>1</td><td>1</td><td>sink-2</td><td>sink-2</td><td>sink-2|sink-2</td><td>1.0</td><td>7.5</td></tr>\n",
       "\t<tr><td>sink</td><td>3   </td><td>sink </td><td>Dam 2</td><td>1.0</td><td>1</td><td>2</td><td>3</td><td>0</td><td>FALSE</td><td>1</td><td>2</td><td>sink-2</td><td>2-3   </td><td>2-3|sink-2   </td><td>2.0</td><td>7.5</td></tr>\n",
       "\t<tr><td>sink</td><td>4   </td><td>sink </td><td>Dam 1</td><td>1.0</td><td>1</td><td>2</td><td>3</td><td>0</td><td>FALSE</td><td>1</td><td>2</td><td>sink-2</td><td>2-4   </td><td>2-4|sink-2   </td><td>2.0</td><td>7.5</td></tr>\n",
       "\t<tr><td>sink</td><td>5   </td><td>sink </td><td>2    </td><td>0.5</td><td>1</td><td>3</td><td>6</td><td>2</td><td>FALSE</td><td>1</td><td>3</td><td>sink-2</td><td>4-5   </td><td>4-5|sink-2   </td><td>1.5</td><td>7.5</td></tr>\n",
       "\t<tr><td>sink</td><td>8   </td><td>sink </td><td>6    </td><td>0.5</td><td>1</td><td>2</td><td>5</td><td>2</td><td>FALSE</td><td>1</td><td>2</td><td>sink-2</td><td>3-8   </td><td>3-8|sink-2   </td><td>1.0</td><td>7.5</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 28 × 17\n",
       "\\begin{tabular}{r|lllllllllllllllll}\n",
       " FromNode & ToNode & FromNodeLabel & ToNodeLabel & CumulativePass & FromEdgeLen & ToEdgeLen & TotalDist & DistMinusStartEndLen & DistMinusSEExceedsThreshold & FromEdgeHab & ToEdgeHab & FromEdgeName & ToEdgeName & ToFromEdgeNameCombo & ToEdgeHabMaxAccessible & MaxTotalAccessHabFromEdge\\\\\n",
       " <chr> & <chr> & <chr> & <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <lgl> & <dbl> & <dbl> & <chr> & <chr> & <chr> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 2    & 3    & 4     & Dam 2 & 1.0 & 2 & 2 & 2 & 0 & FALSE & 2 & 2 & 2-3    & 2-3    & 2-3\\textbar{}2-3       & 2.0 & 7.5\\\\\n",
       "\t 2    & 4    & 4     & Dam 1 & 1.0 & 2 & 2 & 2 & 0 & FALSE & 2 & 2 & 2-4    & 2-4    & 2-4\\textbar{}2-4       & 2.0 & 7.5\\\\\n",
       "\t 2    & 5    & 4     & 2     & 0.5 & 2 & 3 & 5 & 0 & FALSE & 2 & 3 & 2-4    & 4-5    & 4-5\\textbar{}2-4       & 2.0 & 7.5\\\\\n",
       "\t 2    & 8    & 4     & 6     & 0.5 & 2 & 2 & 4 & 0 & FALSE & 2 & 2 & 2-3    & 3-8    & 3-8\\textbar{}2-3       & 1.5 & 7.5\\\\\n",
       "\t 2    & sink & 4     & sink  & 1.0 & 1 & 1 & 1 & 0 & FALSE & 1 & 1 & sink-2 & sink-2 & sink-2\\textbar{}sink-2 & 1.0 & 7.5\\\\\n",
       "\t 3    & 2    & Dam 2 & 4     & 1.0 & 2 & 2 & 2 & 0 & FALSE & 2 & 2 & 2-3    & 2-3    & 2-3\\textbar{}2-3       & 2.0 & 7.5\\\\\n",
       "\t 3    & 4    & Dam 2 & Dam 1 & 1.0 & 2 & 2 & 4 & 0 & FALSE & 2 & 2 & 2-3    & 2-4    & 2-4\\textbar{}2-3       & 1.5 & 7.5\\\\\n",
       "\t 3    & 5    & Dam 2 & 2     & 0.5 & 2 & 3 & 7 & 2 & FALSE & 2 & 3 & 2-3    & 4-5    & 4-5\\textbar{}2-3       & 1.5 & 7.5\\\\\n",
       "\t 3    & 8    & Dam 2 & 6     & 1.0 & 2 & 2 & 2 & 0 & FALSE & 2 & 2 & 3-8    & 3-8    & 3-8\\textbar{}3-8       & 2.0 & 5.0\\\\\n",
       "\t 3    & sink & Dam 2 & sink  & 1.0 & 2 & 1 & 3 & 0 & FALSE & 2 & 1 & 2-3    & sink-2 & sink-2\\textbar{}2-3    & 1.0 & 7.5\\\\\n",
       "\t 4    & 2    & Dam 1 & 4     & 1.0 & 2 & 2 & 2 & 0 & FALSE & 2 & 2 & 2-4    & 2-4    & 2-4\\textbar{}2-4       & 2.0 & 7.5\\\\\n",
       "\t 4    & 3    & Dam 1 & Dam 2 & 1.0 & 2 & 2 & 4 & 0 & FALSE & 2 & 2 & 2-4    & 2-3    & 2-3\\textbar{}2-4       & 1.5 & 7.5\\\\\n",
       "\t 4    & 5    & Dam 1 & 2     & 1.0 & 3 & 3 & 3 & 0 & FALSE & 3 & 3 & 4-5    & 4-5    & 4-5\\textbar{}4-5       & 3.0 & 5.5\\\\\n",
       "\t 4    & 8    & Dam 1 & 6     & 0.5 & 2 & 2 & 6 & 2 & FALSE & 2 & 2 & 2-4    & 3-8    & 3-8\\textbar{}2-4       & 1.0 & 7.5\\\\\n",
       "\t 4    & sink & Dam 1 & sink  & 1.0 & 2 & 1 & 3 & 0 & FALSE & 2 & 1 & 2-4    & sink-2 & sink-2\\textbar{}2-4    & 1.0 & 7.5\\\\\n",
       "\t 5    & 2    & 2     & 4     & 0.5 & 3 & 2 & 5 & 0 & FALSE & 3 & 2 & 4-5    & 2-4    & 2-4\\textbar{}4-5       & 1.0 & 5.5\\\\\n",
       "\t 5    & 3    & 2     & Dam 2 & 0.5 & 3 & 2 & 7 & 2 & FALSE & 3 & 2 & 4-5    & 2-3    & 2-3\\textbar{}4-5       & 1.0 & 5.5\\\\\n",
       "\t 5    & 4    & 2     & Dam 1 & 1.0 & 3 & 3 & 3 & 0 & FALSE & 3 & 3 & 4-5    & 4-5    & 4-5\\textbar{}4-5       & 3.0 & 5.5\\\\\n",
       "\t 5    & sink & 2     & sink  & 0.5 & 3 & 1 & 6 & 2 & FALSE & 3 & 1 & 4-5    & sink-2 & sink-2\\textbar{}4-5    & 0.5 & 5.5\\\\\n",
       "\t 8    & 2    & 6     & 4     & 0.5 & 2 & 2 & 4 & 0 & FALSE & 2 & 2 & 3-8    & 2-3    & 2-3\\textbar{}3-8       & 1.5 & 5.0\\\\\n",
       "\t 8    & 3    & 6     & Dam 2 & 1.0 & 2 & 2 & 2 & 0 & FALSE & 2 & 2 & 3-8    & 3-8    & 3-8\\textbar{}3-8       & 2.0 & 5.0\\\\\n",
       "\t 8    & 4    & 6     & Dam 1 & 0.5 & 2 & 2 & 6 & 2 & FALSE & 2 & 2 & 3-8    & 2-4    & 2-4\\textbar{}3-8       & 1.0 & 5.0\\\\\n",
       "\t 8    & sink & 6     & sink  & 0.5 & 2 & 1 & 5 & 2 & FALSE & 2 & 1 & 3-8    & sink-2 & sink-2\\textbar{}3-8    & 0.5 & 5.0\\\\\n",
       "\t sink & 2    & sink  & 4     & 1.0 & 1 & 1 & 1 & 0 & FALSE & 1 & 1 & sink-2 & sink-2 & sink-2\\textbar{}sink-2 & 1.0 & 7.5\\\\\n",
       "\t sink & 3    & sink  & Dam 2 & 1.0 & 1 & 2 & 3 & 0 & FALSE & 1 & 2 & sink-2 & 2-3    & 2-3\\textbar{}sink-2    & 2.0 & 7.5\\\\\n",
       "\t sink & 4    & sink  & Dam 1 & 1.0 & 1 & 2 & 3 & 0 & FALSE & 1 & 2 & sink-2 & 2-4    & 2-4\\textbar{}sink-2    & 2.0 & 7.5\\\\\n",
       "\t sink & 5    & sink  & 2     & 0.5 & 1 & 3 & 6 & 2 & FALSE & 1 & 3 & sink-2 & 4-5    & 4-5\\textbar{}sink-2    & 1.5 & 7.5\\\\\n",
       "\t sink & 8    & sink  & 6     & 0.5 & 1 & 2 & 5 & 2 & FALSE & 1 & 2 & sink-2 & 3-8    & 3-8\\textbar{}sink-2    & 1.0 & 7.5\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 28 × 17\n",
       "\n",
       "| FromNode &lt;chr&gt; | ToNode &lt;chr&gt; | FromNodeLabel &lt;chr&gt; | ToNodeLabel &lt;chr&gt; | CumulativePass &lt;dbl&gt; | FromEdgeLen &lt;dbl&gt; | ToEdgeLen &lt;dbl&gt; | TotalDist &lt;dbl&gt; | DistMinusStartEndLen &lt;dbl&gt; | DistMinusSEExceedsThreshold &lt;lgl&gt; | FromEdgeHab &lt;dbl&gt; | ToEdgeHab &lt;dbl&gt; | FromEdgeName &lt;chr&gt; | ToEdgeName &lt;chr&gt; | ToFromEdgeNameCombo &lt;chr&gt; | ToEdgeHabMaxAccessible &lt;dbl&gt; | MaxTotalAccessHabFromEdge &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 2    | 3    | 4     | Dam 2 | 1.0 | 2 | 2 | 2 | 0 | FALSE | 2 | 2 | 2-3    | 2-3    | 2-3|2-3       | 2.0 | 7.5 |\n",
       "| 2    | 4    | 4     | Dam 1 | 1.0 | 2 | 2 | 2 | 0 | FALSE | 2 | 2 | 2-4    | 2-4    | 2-4|2-4       | 2.0 | 7.5 |\n",
       "| 2    | 5    | 4     | 2     | 0.5 | 2 | 3 | 5 | 0 | FALSE | 2 | 3 | 2-4    | 4-5    | 4-5|2-4       | 2.0 | 7.5 |\n",
       "| 2    | 8    | 4     | 6     | 0.5 | 2 | 2 | 4 | 0 | FALSE | 2 | 2 | 2-3    | 3-8    | 3-8|2-3       | 1.5 | 7.5 |\n",
       "| 2    | sink | 4     | sink  | 1.0 | 1 | 1 | 1 | 0 | FALSE | 1 | 1 | sink-2 | sink-2 | sink-2|sink-2 | 1.0 | 7.5 |\n",
       "| 3    | 2    | Dam 2 | 4     | 1.0 | 2 | 2 | 2 | 0 | FALSE | 2 | 2 | 2-3    | 2-3    | 2-3|2-3       | 2.0 | 7.5 |\n",
       "| 3    | 4    | Dam 2 | Dam 1 | 1.0 | 2 | 2 | 4 | 0 | FALSE | 2 | 2 | 2-3    | 2-4    | 2-4|2-3       | 1.5 | 7.5 |\n",
       "| 3    | 5    | Dam 2 | 2     | 0.5 | 2 | 3 | 7 | 2 | FALSE | 2 | 3 | 2-3    | 4-5    | 4-5|2-3       | 1.5 | 7.5 |\n",
       "| 3    | 8    | Dam 2 | 6     | 1.0 | 2 | 2 | 2 | 0 | FALSE | 2 | 2 | 3-8    | 3-8    | 3-8|3-8       | 2.0 | 5.0 |\n",
       "| 3    | sink | Dam 2 | sink  | 1.0 | 2 | 1 | 3 | 0 | FALSE | 2 | 1 | 2-3    | sink-2 | sink-2|2-3    | 1.0 | 7.5 |\n",
       "| 4    | 2    | Dam 1 | 4     | 1.0 | 2 | 2 | 2 | 0 | FALSE | 2 | 2 | 2-4    | 2-4    | 2-4|2-4       | 2.0 | 7.5 |\n",
       "| 4    | 3    | Dam 1 | Dam 2 | 1.0 | 2 | 2 | 4 | 0 | FALSE | 2 | 2 | 2-4    | 2-3    | 2-3|2-4       | 1.5 | 7.5 |\n",
       "| 4    | 5    | Dam 1 | 2     | 1.0 | 3 | 3 | 3 | 0 | FALSE | 3 | 3 | 4-5    | 4-5    | 4-5|4-5       | 3.0 | 5.5 |\n",
       "| 4    | 8    | Dam 1 | 6     | 0.5 | 2 | 2 | 6 | 2 | FALSE | 2 | 2 | 2-4    | 3-8    | 3-8|2-4       | 1.0 | 7.5 |\n",
       "| 4    | sink | Dam 1 | sink  | 1.0 | 2 | 1 | 3 | 0 | FALSE | 2 | 1 | 2-4    | sink-2 | sink-2|2-4    | 1.0 | 7.5 |\n",
       "| 5    | 2    | 2     | 4     | 0.5 | 3 | 2 | 5 | 0 | FALSE | 3 | 2 | 4-5    | 2-4    | 2-4|4-5       | 1.0 | 5.5 |\n",
       "| 5    | 3    | 2     | Dam 2 | 0.5 | 3 | 2 | 7 | 2 | FALSE | 3 | 2 | 4-5    | 2-3    | 2-3|4-5       | 1.0 | 5.5 |\n",
       "| 5    | 4    | 2     | Dam 1 | 1.0 | 3 | 3 | 3 | 0 | FALSE | 3 | 3 | 4-5    | 4-5    | 4-5|4-5       | 3.0 | 5.5 |\n",
       "| 5    | sink | 2     | sink  | 0.5 | 3 | 1 | 6 | 2 | FALSE | 3 | 1 | 4-5    | sink-2 | sink-2|4-5    | 0.5 | 5.5 |\n",
       "| 8    | 2    | 6     | 4     | 0.5 | 2 | 2 | 4 | 0 | FALSE | 2 | 2 | 3-8    | 2-3    | 2-3|3-8       | 1.5 | 5.0 |\n",
       "| 8    | 3    | 6     | Dam 2 | 1.0 | 2 | 2 | 2 | 0 | FALSE | 2 | 2 | 3-8    | 3-8    | 3-8|3-8       | 2.0 | 5.0 |\n",
       "| 8    | 4    | 6     | Dam 1 | 0.5 | 2 | 2 | 6 | 2 | FALSE | 2 | 2 | 3-8    | 2-4    | 2-4|3-8       | 1.0 | 5.0 |\n",
       "| 8    | sink | 6     | sink  | 0.5 | 2 | 1 | 5 | 2 | FALSE | 2 | 1 | 3-8    | sink-2 | sink-2|3-8    | 0.5 | 5.0 |\n",
       "| sink | 2    | sink  | 4     | 1.0 | 1 | 1 | 1 | 0 | FALSE | 1 | 1 | sink-2 | sink-2 | sink-2|sink-2 | 1.0 | 7.5 |\n",
       "| sink | 3    | sink  | Dam 2 | 1.0 | 1 | 2 | 3 | 0 | FALSE | 1 | 2 | sink-2 | 2-3    | 2-3|sink-2    | 2.0 | 7.5 |\n",
       "| sink | 4    | sink  | Dam 1 | 1.0 | 1 | 2 | 3 | 0 | FALSE | 1 | 2 | sink-2 | 2-4    | 2-4|sink-2    | 2.0 | 7.5 |\n",
       "| sink | 5    | sink  | 2     | 0.5 | 1 | 3 | 6 | 2 | FALSE | 1 | 3 | sink-2 | 4-5    | 4-5|sink-2    | 1.5 | 7.5 |\n",
       "| sink | 8    | sink  | 6     | 0.5 | 1 | 2 | 5 | 2 | FALSE | 1 | 2 | sink-2 | 3-8    | 3-8|sink-2    | 1.0 | 7.5 |\n",
       "\n"
      ],
      "text/plain": [
       "   FromNode ToNode FromNodeLabel ToNodeLabel CumulativePass FromEdgeLen\n",
       "1  2        3      4             Dam 2       1.0            2          \n",
       "2  2        4      4             Dam 1       1.0            2          \n",
       "3  2        5      4             2           0.5            2          \n",
       "4  2        8      4             6           0.5            2          \n",
       "5  2        sink   4             sink        1.0            1          \n",
       "6  3        2      Dam 2         4           1.0            2          \n",
       "7  3        4      Dam 2         Dam 1       1.0            2          \n",
       "8  3        5      Dam 2         2           0.5            2          \n",
       "9  3        8      Dam 2         6           1.0            2          \n",
       "10 3        sink   Dam 2         sink        1.0            2          \n",
       "11 4        2      Dam 1         4           1.0            2          \n",
       "12 4        3      Dam 1         Dam 2       1.0            2          \n",
       "13 4        5      Dam 1         2           1.0            3          \n",
       "14 4        8      Dam 1         6           0.5            2          \n",
       "15 4        sink   Dam 1         sink        1.0            2          \n",
       "16 5        2      2             4           0.5            3          \n",
       "17 5        3      2             Dam 2       0.5            3          \n",
       "18 5        4      2             Dam 1       1.0            3          \n",
       "19 5        sink   2             sink        0.5            3          \n",
       "20 8        2      6             4           0.5            2          \n",
       "21 8        3      6             Dam 2       1.0            2          \n",
       "22 8        4      6             Dam 1       0.5            2          \n",
       "23 8        sink   6             sink        0.5            2          \n",
       "24 sink     2      sink          4           1.0            1          \n",
       "25 sink     3      sink          Dam 2       1.0            1          \n",
       "26 sink     4      sink          Dam 1       1.0            1          \n",
       "27 sink     5      sink          2           0.5            1          \n",
       "28 sink     8      sink          6           0.5            1          \n",
       "   ToEdgeLen TotalDist DistMinusStartEndLen DistMinusSEExceedsThreshold\n",
       "1  2         2         0                    FALSE                      \n",
       "2  2         2         0                    FALSE                      \n",
       "3  3         5         0                    FALSE                      \n",
       "4  2         4         0                    FALSE                      \n",
       "5  1         1         0                    FALSE                      \n",
       "6  2         2         0                    FALSE                      \n",
       "7  2         4         0                    FALSE                      \n",
       "8  3         7         2                    FALSE                      \n",
       "9  2         2         0                    FALSE                      \n",
       "10 1         3         0                    FALSE                      \n",
       "11 2         2         0                    FALSE                      \n",
       "12 2         4         0                    FALSE                      \n",
       "13 3         3         0                    FALSE                      \n",
       "14 2         6         2                    FALSE                      \n",
       "15 1         3         0                    FALSE                      \n",
       "16 2         5         0                    FALSE                      \n",
       "17 2         7         2                    FALSE                      \n",
       "18 3         3         0                    FALSE                      \n",
       "19 1         6         2                    FALSE                      \n",
       "20 2         4         0                    FALSE                      \n",
       "21 2         2         0                    FALSE                      \n",
       "22 2         6         2                    FALSE                      \n",
       "23 1         5         2                    FALSE                      \n",
       "24 1         1         0                    FALSE                      \n",
       "25 2         3         0                    FALSE                      \n",
       "26 2         3         0                    FALSE                      \n",
       "27 3         6         2                    FALSE                      \n",
       "28 2         5         2                    FALSE                      \n",
       "   FromEdgeHab ToEdgeHab FromEdgeName ToEdgeName ToFromEdgeNameCombo\n",
       "1  2           2         2-3          2-3        2-3|2-3            \n",
       "2  2           2         2-4          2-4        2-4|2-4            \n",
       "3  2           3         2-4          4-5        4-5|2-4            \n",
       "4  2           2         2-3          3-8        3-8|2-3            \n",
       "5  1           1         sink-2       sink-2     sink-2|sink-2      \n",
       "6  2           2         2-3          2-3        2-3|2-3            \n",
       "7  2           2         2-3          2-4        2-4|2-3            \n",
       "8  2           3         2-3          4-5        4-5|2-3            \n",
       "9  2           2         3-8          3-8        3-8|3-8            \n",
       "10 2           1         2-3          sink-2     sink-2|2-3         \n",
       "11 2           2         2-4          2-4        2-4|2-4            \n",
       "12 2           2         2-4          2-3        2-3|2-4            \n",
       "13 3           3         4-5          4-5        4-5|4-5            \n",
       "14 2           2         2-4          3-8        3-8|2-4            \n",
       "15 2           1         2-4          sink-2     sink-2|2-4         \n",
       "16 3           2         4-5          2-4        2-4|4-5            \n",
       "17 3           2         4-5          2-3        2-3|4-5            \n",
       "18 3           3         4-5          4-5        4-5|4-5            \n",
       "19 3           1         4-5          sink-2     sink-2|4-5         \n",
       "20 2           2         3-8          2-3        2-3|3-8            \n",
       "21 2           2         3-8          3-8        3-8|3-8            \n",
       "22 2           2         3-8          2-4        2-4|3-8            \n",
       "23 2           1         3-8          sink-2     sink-2|3-8         \n",
       "24 1           1         sink-2       sink-2     sink-2|sink-2      \n",
       "25 1           2         sink-2       2-3        2-3|sink-2         \n",
       "26 1           2         sink-2       2-4        2-4|sink-2         \n",
       "27 1           3         sink-2       4-5        4-5|sink-2         \n",
       "28 1           2         sink-2       3-8        3-8|sink-2         \n",
       "   ToEdgeHabMaxAccessible MaxTotalAccessHabFromEdge\n",
       "1  2.0                    7.5                      \n",
       "2  2.0                    7.5                      \n",
       "3  2.0                    7.5                      \n",
       "4  1.5                    7.5                      \n",
       "5  1.0                    7.5                      \n",
       "6  2.0                    7.5                      \n",
       "7  1.5                    7.5                      \n",
       "8  1.5                    7.5                      \n",
       "9  2.0                    5.0                      \n",
       "10 1.0                    7.5                      \n",
       "11 2.0                    7.5                      \n",
       "12 1.5                    7.5                      \n",
       "13 3.0                    5.5                      \n",
       "14 1.0                    7.5                      \n",
       "15 1.0                    7.5                      \n",
       "16 1.0                    5.5                      \n",
       "17 1.0                    5.5                      \n",
       "18 3.0                    5.5                      \n",
       "19 0.5                    5.5                      \n",
       "20 1.5                    5.0                      \n",
       "21 2.0                    5.0                      \n",
       "22 1.0                    5.0                      \n",
       "23 0.5                    5.0                      \n",
       "24 1.0                    7.5                      \n",
       "25 2.0                    7.5                      \n",
       "26 2.0                    7.5                      \n",
       "27 1.5                    7.5                      \n",
       "28 1.0                    7.5                      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum_tab_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8849278f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'toedge_maxaccessible' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'toedge_maxaccessible' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "toedge_maxaccessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83850524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
